{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbdb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Exploratory data analysis :\n",
    "    \n",
    "Dataset consist of following columns: 'country', 'country_long', 'name', 'gppd_idnr', 'capacity_mw',\n",
    "       'latitude', 'longitude', 'primary_fuel', 'other_fuel1', 'other_fuel2',\n",
    "       'other_fuel3', 'commissioning_year', 'owner', 'source', 'url',\n",
    "       'geolocation_source', 'wepp_id', 'year_of_capacity_data',\n",
    "       'generation_gwh_2013', 'generation_gwh_2014', 'generation_gwh_2015',\n",
    "       'generation_gwh_2016', 'generation_gwh_2017', 'generation_gwh_2018',\n",
    "       'generation_gwh_2019', 'generation_data_source',\n",
    "       'estimated_generation_gwh'\n",
    "       \n",
    "There are 907 rows and 27 columns.\n",
    "\n",
    "Following are data types of columns:\n",
    "country                      object\n",
    "country_long                 object\n",
    "name                         object\n",
    "gppd_idnr                    object\n",
    "capacity_mw                 float64\n",
    "latitude                    float64\n",
    "longitude                   float64\n",
    "primary_fuel                 object\n",
    "other_fuel1                  object\n",
    "other_fuel2                  object\n",
    "other_fuel3                 float64\n",
    "commissioning_year          float64\n",
    "owner                        object\n",
    "source                       object\n",
    "url                          object\n",
    "geolocation_source           object\n",
    "wepp_id                     float64\n",
    "year_of_capacity_data       float64\n",
    "generation_gwh_2013         float64\n",
    "generation_gwh_2014         float64\n",
    "generation_gwh_2015         float64\n",
    "generation_gwh_2016         float64\n",
    "generation_gwh_2017         float64\n",
    "generation_gwh_2018         float64\n",
    "generation_gwh_2019         float64\n",
    "generation_data_source       object\n",
    "estimated_generation_gwh    float64\n",
    "\n",
    "We can see that dataset contanis lot of null values.\n",
    "\n",
    "estimated_generation_gwh    907\n",
    "other_fuel3                 907\n",
    "wepp_id                     907\n",
    "generation_gwh_2013         907\n",
    "generation_gwh_2019         907\n",
    "other_fuel2                 906\n",
    "other_fuel1                 709\n",
    "owner                       565\n",
    "generation_gwh_2014         509\n",
    "generation_gwh_2015         485\n",
    "generation_gwh_2016         473\n",
    "generation_gwh_2017         467\n",
    "generation_gwh_2018         459\n",
    "generation_data_source      458\n",
    "year_of_capacity_data       388\n",
    "commissioning_year          380\n",
    "\n",
    "Mostly null values can be seen in above columns.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Large variation can be seen between max and min and mean values of capacity_mw and all generation_gwh columns\n",
    "\n",
    "TOP FREQUENCIES\n",
    "\n",
    "For country and country_long there is only one unique value.\n",
    "\n",
    "ACME Solar Tower has top frequency in names.\n",
    "\n",
    "WRI1020239 has top frequency in gppd_idnr.\n",
    "\n",
    "primary_fuel has top frequency coal.\n",
    "\n",
    "generation_data_source,owner, commissioning_year: most values are not available.\n",
    "    \n",
    "in source, Central Electricity Authority has top freq.\n",
    "\n",
    "Most url have http://www.cea.nic.in/ value.\n",
    "    \n",
    "geolocation_source wri.\n",
    "\n",
    "year_of_capacity_data: 2019\n",
    "\n",
    "We are dropping left null values of: latitude,longitude,geolocation_source\n",
    "\n",
    "By looking at max min mean values: outliers presence can be felt.\n",
    "\n",
    "List of categorical columns: ['country', 'country_long', 'name', 'gppd_idnr', 'primary_fuel',\n",
    "       'commissioning_year', 'owner', 'source', 'url', 'geolocation_source',\n",
    "       'year_of_capacity_data', 'generation_data_source']\n",
    "    \n",
    "List of numerical columns: ['capacity_mw', 'latitude', 'longitude', 'generation_gwh_2014',\n",
    "       'generation_gwh_2015', 'generation_gwh_2016', 'generation_gwh_2017',\n",
    "       'generation_gwh_2018']\n",
    "       \n",
    "For country , most frequent value is:  ModeResult(mode=array(['IND'], dtype=object), count=array([861])) \n",
    "\n",
    "For country_long , most frequent value is:  ModeResult(mode=array(['India'], dtype=object), count=array([861])) \n",
    "\n",
    "For name , most frequent value is:  ModeResult(mode=array(['ACME Solar Tower'], dtype=object), count=array([1])) \n",
    "\n",
    "For gppd_idnr , most frequent value is:  ModeResult(mode=array(['IND0000001'], dtype=object), count=array([1])) \n",
    "\n",
    "For primary_fuel , most frequent value is:  ModeResult(mode=array(['Coal'], dtype=object), count=array([253])) \n",
    "\n",
    "\n",
    "Checking frequencies: \n",
    "\n",
    "For primary fuel\n",
    "Highest:\n",
    "coal and hydro has highest\n",
    "Lowest:\n",
    "Oil and nuclear\n",
    "\n",
    "For commisioning year\n",
    "Highest not available data\n",
    "Lowest: before 1972\n",
    "\n",
    "For source\n",
    "Highest central electricity\n",
    "\n",
    "For geolocation source\n",
    "Highest wri\n",
    "Lowest NREL\n",
    "\n",
    "For yearofcapacity\n",
    "Highest NA\n",
    "Lowest 2019\n",
    "\n",
    "scatterplot between latitude and longitude and capacity predict low frequencies when capacity > 1500\n",
    "A trend can be seen between capacity and all generation_gwh columns\n",
    "WRI has highest range of frequencies.\n",
    "All gemeration_gwh features are related to each other.\n",
    "Mostly data points lie between 5000 gewolocation gwh and 1000 for capacity mw\n",
    "\n",
    "WRi geolocation source has variety of options for primary fuel.\n",
    "NREl and industry about rely on solar for primary fuel\n",
    "Coal and hydro produce max capacity_mw.\n",
    "Central electricity authority produces max capacity_mw\n",
    "\n",
    "Using relational plots:\n",
    "\n",
    "All generation_gwh features are positively related with capacity_mw\n",
    "No clear relation can be seen between latitude longitude and capacity mw\n",
    "\n",
    "Analysing histogram data:\n",
    "\n",
    "Feature: capacity mw\n",
    "max frequency range 0 to 1000\n",
    "min frequency range 1000 to 4000\n",
    "\n",
    "Feature: latitude\n",
    "max frequency range 15 to 28\n",
    "\n",
    "Feature: longitude\n",
    "max frequency range 72 to 80\n",
    "\n",
    "Feature: generation_gwh\n",
    "max frequency range 0 to 5000\n",
    "\n",
    "Analysing outliers:\n",
    "All numerical columns except latitude have outliers\n",
    "\n",
    "Coal wri and central electricty aut. being having highest range of values have lot of outliers as well.\n",
    "\n",
    "Analysing fuels:\n",
    "Biomass nuclear and oil have least relation with capacity mw.\n",
    "\n",
    "Coal hydro and gas have good +ive relation with capacity mw.\n",
    "\n",
    "Analysing skewness:\n",
    "\n",
    "generation_gwh features and capacity_mw have highest skewness due to presence of large outliers.\n",
    "\n",
    "4.18 percent of outliers are removed.\n",
    "\n",
    "Now we have skewness underlimit\n",
    "latitude              -0.108047\n",
    "longitude              0.967396\n",
    "generation_gwh_2017    1.280814\n",
    "generation_gwh_2018    1.319552\n",
    "generation_gwh_2015    1.389486\n",
    "generation_gwh_2016    1.410976\n",
    "generation_gwh_2014    1.515514\n",
    "capacity_mw            1.945004\n",
    "\n",
    "analysing correlation:\n",
    "All the features can be seen +ively correlated with target column.\n",
    "\n",
    "analysing multicollinearity:\n",
    "All generation gwh columns are highly correlated with each other which is confirmed using vif.\n",
    "\n",
    "Furthur using PowerTransformer, Principal Component Analysis that is a diamensionallity reduction technique,\n",
    "we proceed with model instantiation and evaluation:\n",
    "\n",
    "For regression:\n",
    "\n",
    "MODEL USED XGBOOST\n",
    "\n",
    "MAE:  104.17561739620085\n",
    "MSE:  28244.294577172477\n",
    "RMSE:  168.06038967339234\n",
    "R2:  0.8165421300307603 \n",
    "\n",
    "Score:  1.0\n",
    "\n",
    "For classification\n",
    "\n",
    "Training accuracy:  100.0\n",
    "Testing accuracy:  82.25806451612904\n",
    "Confusion matrix: \n",
    " [[17  3  0  0  0  0  0  0]\n",
    " [ 1 53  2 10  0  1  0  0]\n",
    " [ 0  3  2  7  0  2  0  0]\n",
    " [ 0  6  7 69  0  0  0  0]\n",
    " [ 0  0  0  1  0  0  0  0]\n",
    " [ 0  0  0  1  0  1  0  0]\n",
    " [ 0  0  0  0  0  0 25  0]\n",
    " [ 0  0  0  0  0  0  0 37]]\n",
    "classification report:                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.85      0.89        20\n",
    "           1       0.82      0.79      0.80        67\n",
    "           2       0.18      0.14      0.16        14\n",
    "           3       0.78      0.84      0.81        82\n",
    "           4       0.00      0.00      0.00         1\n",
    "           5       0.25      0.50      0.33         2\n",
    "           6       1.00      1.00      1.00        25\n",
    "           7       1.00      1.00      1.00        37\n",
    "\n",
    "    accuracy                           0.82       248\n",
    "   macro avg       0.62      0.64      0.63       248\n",
    "weighted avg       0.82      0.82      0.82       248\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7de777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imp libs:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Spliting data\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Importing metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba3bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing and Normalizing data:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "# Spliting data\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "# Importing metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "# Removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa397b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = 'https://raw.githubusercontent.com/wri/global-power-plant-database/master/source_databases_csv/database_IND.csv'\n",
    "df = pd.read_csv(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First 10 rows')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc587b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Last 10 rows')\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f071e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ec5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acbe680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_data = df.isnull().sum()\n",
    "null_data.sort_values(ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f70bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cols= ['estimated_generation_gwh','other_fuel3','wepp_id','generation_gwh_2013','generation_gwh_2019','other_fuel2',\n",
    "            'other_fuel1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29009e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=null_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Furthur treating null values:\n",
    "\n",
    "df['owner'].fillna('Not available',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb180ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generation_gwh_2014'].fillna(np.mean(df['generation_gwh_2014']),axis=0,inplace=True)        \n",
    "df['generation_gwh_2015'].fillna(np.mean(df['generation_gwh_2015']),axis=0,inplace=True)         \n",
    "df['generation_gwh_2016'].fillna(np.mean(df['generation_gwh_2016']),axis=0,inplace=True)\n",
    "df['generation_gwh_2017'].fillna(np.mean(df['generation_gwh_2017']),axis=0,inplace=True)         \n",
    "df['generation_gwh_2018'].fillna(np.mean(df['generation_gwh_2018']),axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f76736",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generation_data_source'].fillna('Not available',axis=0,inplace=True)\n",
    "df['year_of_capacity_data'].fillna('Not available',axis=0,inplace=True)\n",
    "df['commissioning_year'].fillna('Not available',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc430d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Null value treatment:\n",
    "Lets fill missing values with mean values for generation columns.\n",
    "For generation_data_source, year_of_capacity_data, commissioning_year since we dont know exact values\n",
    "lets fill them using not available value\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = df.describe().T\n",
    "desc['range']=desc['max']-desc['min']\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object').T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed87297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc[['min','mean','max','range']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bc7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_data = df.select_dtypes(include=['int64','float64'])\n",
    "\n",
    "cat_data= df.select_dtypes(include=['object'])\n",
    "\n",
    "cont_columns = cont_data.columns\n",
    "\n",
    "cat_columns = cat_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62234a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a100c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for i in ['country', 'country_long', 'name', 'gppd_idnr', 'primary_fuel']:\n",
    "    print('For',i,', most frequent value is: ',stats.mode(df[i]),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_columns:\n",
    "    print('For column',i,'unique values are: ',df[i].unique())\n",
    "    print('For column',i,'count of unique values are: ',df[i].nunique(),'\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_columns:\n",
    "    print('For column --',i,'-- value counts are: \\n',df[i].value_counts(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ecb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f481c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_fuel = df.groupby(['primary_fuel','owner'])\n",
    "group_fuel.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe01ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp1 = df.groupby(['primary_fuel','capacity_mw'])\n",
    "grp1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ccb233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis:\n",
    "\n",
    "# COUNTPLOT\n",
    "\n",
    "for i in cat_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.countplot(x=df[i],data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da729ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.scatterplot(x=df[i],y='capacity_mw',data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6da026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate analysis\n",
    "\n",
    "# Scaterplot\n",
    "\n",
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.scatterplot(x=df[i],y='geolocation_source',data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a634b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.scatterplot(x=df[i],y='generation_gwh_2018',data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.scatterplot(x=df[i],y='generation_gwh_2018',data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.scatterplot(x=df[i],y='generation_gwh_2017',data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.scatterplot(x=df[i],y='generation_gwh_2016',data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.scatterplot(x=df[i],y='generation_gwh_2015',data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c061a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.scatterplot(x=df[i],y='generation_gwh_2014',data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.scatterplot(x=df[i],y='longitude',data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cfa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.scatterplot(x=df[i],y='latitude',data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c500a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catplots\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.swarmplot(x='primary_fuel',y='geolocation_source',data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.swarmplot(x='primary_fuel',y='generation_data_source',data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.swarmplot(x='primary_fuel',y='source',data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.swarmplot(x='gppd_idnr',y='capacity_mw',data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992cdde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.swarmplot(x='primary_fuel',y='capacity_mw',data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94bb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.swarmplot(x='source',y='capacity_mw',data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ced209",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.swarmplot(x='generation_data_source',y='capacity_mw',data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ff1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4910369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d55708",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('generation_gwh_2015','capacity_mw',data=df,hue='generation_data_source')\n",
    "plt.xlabel('generation_gwh_2015')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00959dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('generation_gwh_2016','capacity_mw',data=df,hue='generation_data_source')\n",
    "plt.xlabel('generation_gwh_2016')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('generation_gwh_2017','capacity_mw',data=df,hue='generation_data_source')\n",
    "plt.xlabel('generation_gwh_2017')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('generation_gwh_2018','capacity_mw',data=df,hue='generation_data_source')\n",
    "plt.xlabel('generation_gwh_2018')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb344119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('generation_gwh_2016','capacity_mw',data=df,hue='commissioning_year')\n",
    "plt.xlabel('generation_gwh_2016')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb41316",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('generation_gwh_2018','capacity_mw',data=df,hue='commissioning_year')\n",
    "plt.xlabel('generation_gwh_2018')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('generation_gwh_2017','capacity_mw',data=df,hue='commissioning_year')\n",
    "plt.xlabel('generation_gwh_2017')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('generation_gwh_2015','capacity_mw',data=df,hue='commissioning_year')\n",
    "plt.xlabel('generation_gwh_2015')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('generation_gwh_2014','capacity_mw',data=df,hue='commissioning_year')\n",
    "plt.xlabel('generation_gwh_2014')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d309805",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('longitude','capacity_mw',data=df,hue='commissioning_year')\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.relplot('latitude','capacity_mw',data=df,hue='primary_fuel')\n",
    "plt.xlabel('latitude')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcff0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b85c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relation plots:\n",
    "\n",
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(12,5))\n",
    "    sns.relplot(df[i],'capacity_mw',data=df,hue='source')\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('capacity_mw')\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineplot\n",
    "\n",
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(12,5))\n",
    "    sns.lineplot(df[i],'capacity_mw',data=df)\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('capacity_mw')\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis using frequency, density and box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hist plot\n",
    "\n",
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.histplot(x=df[i])\n",
    "    plt.xlabel(i)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel density estimation plot\n",
    "\n",
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.kdeplot(x=df[i])\n",
    "    plt.xlabel(i)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affdf7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plot\n",
    "\n",
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.distplot(x=df[i])\n",
    "    plt.xlabel(i)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37569fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Box plot\n",
    "\n",
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.boxplot(x=df[i])\n",
    "    plt.xlabel(i)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catplot of box kind:\n",
    "\n",
    "f= plt.figure(figsize=(12,5))\n",
    "ax = sns.catplot(x='primary_fuel',y='capacity_mw',kind='box',data=df)\n",
    "plt.xlabel('primary_fuel')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcaac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax = sns.catplot(x='generation_data_source',y='capacity_mw',kind='box',data=df)\n",
    "plt.xlabel('generation_data_source')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4902095",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax = sns.catplot(x='year_of_capacity_data',y='capacity_mw',kind='box',data=df)\n",
    "plt.xlabel('year_of_capacity_data')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax = sns.catplot(x='geolocation_source',y='capacity_mw',kind='box',data=df)\n",
    "plt.xlabel('geolocation_source')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c49db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catplot of box kind:\n",
    "\n",
    "f= plt.figure(figsize=(12,5))\n",
    "ax = sns.catplot(x='commissioning_year',y='capacity_mw',kind='box',data=df)\n",
    "plt.xlabel('commissioning_year')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e75a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catplot of box kind:\n",
    "\n",
    "f= plt.figure(figsize=(12,5))\n",
    "ax = sns.catplot(x='geolocation_source',y='capacity_mw',kind='box',data=df,hue='primary_fuel')\n",
    "plt.xlabel('commissioning_year')\n",
    "plt.ylabel('capacity_mw')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f693d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking linear relation between features and lables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167869b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"latitude\", y = \"capacity_mw\", data=df,hue='primary_fuel', palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1965d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"longitude\", y = \"capacity_mw\", data=df,hue='primary_fuel', palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"generation_gwh_2014\", y = \"capacity_mw\",hue='primary_fuel', data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df48fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"generation_gwh_2015\", y = \"capacity_mw\",hue='primary_fuel', data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"generation_gwh_2016\", y = \"capacity_mw\",hue='primary_fuel', data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"generation_gwh_2017\", y = \"capacity_mw\",hue='primary_fuel', data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a185ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"generation_gwh_2018\", y = \"capacity_mw\",hue='primary_fuel', data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e3592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking skewness and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21565d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Z Statistics to check and remove any more outliers:\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_score = zscore(df[cont_columns])\n",
    "\n",
    "abs_z_score = np.abs(z_score)\n",
    "\n",
    "filtering_entry = (abs_z_score < 3).all(axis=1) # values lying in 3 times std will be removed\n",
    "\n",
    "df = df[filtering_entry]\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ca93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "861-825 # outliers deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c436649",
   "metadata": {},
   "outputs": [],
   "source": [
    "36/861*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffabf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of continuous variables:\n",
    "\n",
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.distplot(df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deedb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features and label:\n",
    "\n",
    "# Replacing attrition column values:\n",
    "\n",
    "df.drop(columns = 'capacity_mw',axis = 1).corrwith(df.capacity_mw).plot(kind='bar',grid=True,figsize=(10,7),title='corelation between features and labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee90131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr().abs()\n",
    "plt.figure(figsize=(25,22))\n",
    "sns.heatmap(df_corr,annot=True,annot_kws={'size':10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3946d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['vif'] = [variance_inflation_factor(df[cont_columns],i) for i in range(df[cont_columns].shape[1])]\n",
    "vif['features'] = df[cont_columns].columns\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_new.columns:\n",
    "    print(i ,':',df_new[i].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db931e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "data_trans = pt.fit_transform(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d028c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and label:\n",
    "\n",
    "y = df_new['capacity_mw']\n",
    "X = df_new.drop('capacity_mw',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc1de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "X_trans = pt.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Using PCA i.e. Principal Component Analysis that is a diamensionallity reduction technique:\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit_transform(X_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scree Plot to identify best components:\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Covered')\n",
    "plt.title('PCA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=800)\n",
    "new_pcomp = pca.fit_transform(X_trans)\n",
    "princi_comp = pd.DataFrame(new_pcomp)\n",
    "princi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d85dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "princi_comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in princi_comp.columns:\n",
    "    print(i ,':',princi_comp[i].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef857b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data to training data and testing data\n",
    "# x_train,x_test,y_train,y_test\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(princi_comp,y,test_size=0.30,random_state=1)\n",
    "\n",
    "# Here we are keeping training data as our scalled data and testing data as our label or target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdcfb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOdel instantiating and training\n",
    "\n",
    "rm = LinearRegression()\n",
    "rm.fit(x_train,y_train) \n",
    "# here we will pass training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537378c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our model with Adjusted R2 Square: \n",
    "\n",
    "# on training data\n",
    "\n",
    "rm.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ad2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLotting and visualizing\n",
    "\n",
    "y_pred = rm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bbfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('Actual Charges')\n",
    "plt.ylabel('Predicted Charges')\n",
    "plt.title('Actual vs Model Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e953eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: MAE , MSE , RMSE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "mean_absolute_error(y_test,y_pred) # 4 % error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,y_pred) # lesser the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f4f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d4f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score: \", rm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso,RidgeCV,LassoCV\n",
    "\n",
    "lassocv = LassoCV(alphas = None , max_iter = 100, normalize = True)\n",
    "lassocv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da20360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best alpha parameter\n",
    "alpha = lassocv.alpha_ # Best alpha rate\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd83273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now since we have the best parameter, lasso regression will be used:\n",
    "lasso_reg = Lasso(alpha)\n",
    "lasso_reg.fit(x_train,y_train)\n",
    "# i.e. when model is training it will learn at this speed 6...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Method:\n",
    "\n",
    "ridgecv = RidgeCV(alphas = np.arange(0.001,0.1,0.01),normalize = True)\n",
    "ridgecv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv.alpha_ # Best alpha rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3684d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha = ridgecv.alpha_)\n",
    "ridge_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb09940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rm.coef_)\n",
    "print(f\"{rm.intercept_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609670e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using decision tree:\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_preddt = model.predict(x_test)\n",
    "\n",
    "r2_score(y_test,y_preddt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609bb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest:\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor_rf = RandomForestRegressor(n_estimators = 100)\n",
    "\n",
    "regressor_rf.fit(x_train, y_train)\n",
    "\n",
    "lr_normal_rf = regressor_rf.score(x_train, y_train)\n",
    "\n",
    "lr_normal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abba9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predrf = regressor_rf.predict(x_test)\n",
    "\n",
    "lr_normal_rf_test = regressor_rf.score(x_test, y_test)\n",
    "\n",
    "lr_normal_rf_test\n",
    "\n",
    "mse_lr_normal_rf  = mean_absolute_error(y_test, y_predrf)\n",
    "\n",
    "mse_lr_normal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: MAE , MSE , RMSE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_predrf))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test, y_predrf))\n",
    "print(\"RMSE: \", metrics.mean_squared_error(y_test, y_predrf, squared=False))\n",
    "print(\"R2: \", metrics.r2_score(y_test, y_predrf), \"\\n\")\n",
    "print(\"Score: \", regressor_rf.score(x_test, y_predrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88963f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Support vector regressor:\n",
    "\n",
    "# Fit the model over the training data\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "svr.fit(x_train, y_train)\n",
    "\n",
    "y_predsvr = svr.predict(x_test)\n",
    "\n",
    "r2_score(y_test,y_predsvr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dba6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using XGBoost:\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor()\n",
    "xgb_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e521d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using XGBoost:\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor()\n",
    "xgb_clf.fit(x_train,y_train)\n",
    "\n",
    "y_predx = xgb_clf.predict(x_test)\n",
    "\n",
    "r2_score(y_test,y_predx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for xgboost model\n",
    "\n",
    "params = {\"learning_rate\"    : [0.05, 0.10] ,\n",
    "         \"max_depth\"        : [ 3, 5, 8, 12]}\n",
    "\n",
    "grd = GridSearchCV(xgb_clf,param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_boosted = grd.fit(x_train,y_train)\n",
    "\n",
    "y_predxx = xgb_boosted.predict(x_test)\n",
    "\n",
    "r2_score(y_test,y_predxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e43f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: MAE , MSE , RMSE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_predxx))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test, y_predxx))\n",
    "print(\"RMSE: \", metrics.mean_squared_error(y_test, y_predxx, squared=False))\n",
    "print(\"R2: \", metrics.r2_score(y_test, y_predxx), \"\\n\")\n",
    "print(\"Score: \", xgb_boosted.score(x_test, y_predxx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Innitiate k neighbour Regressor:\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "knnmodel = GridSearchCV(knn, params, cv=5)\n",
    "knnmodel.fit(x_train,y_train)\n",
    "knnmodel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0925a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best = KNeighborsRegressor(n_neighbors = 2)\n",
    "knn_best.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predknn = knn_best.predict(x_test)\n",
    "\n",
    "r2_score(y_test,y_predknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d661757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl = df.copy()\n",
    "df_cl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe112bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and label:\n",
    "\n",
    "y = df_cl['primary_fuel']\n",
    "X = df_cl.drop('primary_fuel',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e0dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding training data:\n",
    "X_dummies = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ed003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding lables:\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl = LabelEncoder()\n",
    "y_enc = lbl.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930312a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a185ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "X_trans_cl = pt.fit_transform(X_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Using PCA i.e. Principal Component Analysis that is a diamensionallity reduction technique:\n",
    "\n",
    "pca1 = PCA()\n",
    "pca1.fit_transform(X_trans_cl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scree Plot to identify best components:\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca1.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Covered')\n",
    "plt.title('PCA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=800)\n",
    "new_pcomp = pca1.fit_transform(X_trans)\n",
    "princi_comp = pd.DataFrame(new_pcomp)\n",
    "princi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc60783",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, y_test = train_test_split(princi_comp, y_enc, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", Y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", x_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '7': {}\".format(sum(Y_train==7)))\n",
    "print(\"Before OverSampling, counts of label '6': {}\".format(sum(Y_train==6)))\n",
    "print(\"Before OverSampling, counts of label '5': {}\".format(sum(Y_train==5)))\n",
    "print(\"Before OverSampling, counts of label '4': {}\".format(sum(Y_train==4)))\n",
    "print(\"Before OverSampling, counts of label '3': {}\".format(sum(Y_train==3)))\n",
    "print(\"Before OverSampling, counts of label '2': {}\".format(sum(Y_train==2)))\n",
    "print(\"Before OverSampling, counts of label '1': {} \\n\".format(sum(Y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(Y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, Y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '7': {}\".format(sum(y_train_res==7)))\n",
    "print(\"After OverSampling, counts of label '6': {}\".format(sum(y_train_res==6)))\n",
    "print(\"After OverSampling, counts of label '5': {}\".format(sum(y_train_res==5)))\n",
    "print(\"After OverSampling, counts of label '4': {}\".format(sum(y_train_res==4)))\n",
    "print(\"After OverSampling, counts of label '3': {}\".format(sum(y_train_res==3)))\n",
    "print(\"After OverSampling, counts of label '2': {}\".format(sum(y_train_res==2)))\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c67205",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(y_train_res)\n",
    "\n",
    "un, co = np.unique(arr,return_counts=True)\n",
    "\n",
    "dict(zip(un,co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression:\n",
    "\n",
    "log_reg = LogisticRegression(random_state=1)\n",
    "\n",
    "log_reg.fit(X_train_res,y_train_res) \n",
    "\n",
    "pred_train = log_reg.predict(X_train_res)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "print('Accuracy report: ',acc)\n",
    "\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "\n",
    "clr = classification_report(y_test,y_pred)\n",
    "\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89107e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best result for Decision Tree Classifier:\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=1)\n",
    "dtc.fit(X_train_res,y_train_res) \n",
    "pred_train_dtc = dtc.predict(X_train_res)\n",
    "y_pred = dtc.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_dtc)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b74924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forrest classifier model:\n",
    "\n",
    "rfc_f = RandomForestClassifier()\n",
    "rfc_f.fit(X_train_res,y_train_res) \n",
    "pred_train_rfc_f = rfc_f.predict(X_train_res)\n",
    "y_pred = rfc_f.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_rfc_f)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9aac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using best parameters for improved score:\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train_res,y_train_res)\n",
    "\n",
    "pred_train_svc = svc.predict(X_train_res)\n",
    "y_pred = svc.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_svc)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a16f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier:\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_res,y_train_res) \n",
    "pred_train_knn = knn.predict(X_train_res)\n",
    "y_pred = knn.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_knn)*100)\n",
    "print('Testing accuracy: ', acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e9da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# GBC\n",
    "\n",
    "gbdt_clf = GradientBoostingClassifier(random_state=3)\n",
    "gbdt_clf.fit(X_train_res,y_train_res) \n",
    "pred_train_gbdt_clf = gbdt_clf.predict(X_train_res)\n",
    "y_pred = gbdt_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_gbdt_clf)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADA model:\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_boosted = AdaBoostClassifier()\n",
    "ada_boosted.fit(X_train_res,y_train_res)\n",
    "yb_pred = ada_boosted.predict(X_test)\n",
    "pred_train_ada = ada_boosted.predict(X_train_res)\n",
    "y_pred = ada_boosted.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_ada)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train_res, y_train_res)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "  \n",
    "# accuracy on X_test\n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot ROC AUC curve to choose best model:\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc73164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosing best models for classification and regression problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best random state for RandomForestregressor model:\n",
    "\n",
    "maxAccu = 0\n",
    "maxRS = 0\n",
    "\n",
    "for i in range(1,200):\n",
    "    regressor_rf = RandomForestRegressor(n_estimators = 100)\n",
    "    regressor_rf.fit(X_train_res,y_train_res) \n",
    "    y_pred = regressor_rf.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Testing accuracy: ', acc, 'at random state', i)\n",
    "    \n",
    "    if acc > maxAccu:\n",
    "        maxAccu = acc\n",
    "        maxRS = i\n",
    "        print('Max accuracy',maxAccu,'max random state',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ccf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest:\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor_rf = RandomForestRegressor(n_estimators = 100)\n",
    "\n",
    "regressor_rf.fit(x_train, y_train)\n",
    "\n",
    "lr_normal_rf = regressor_rf.score(x_train, y_train)\n",
    "\n",
    "lr_normal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccaf2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fffab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfe44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our besy model for classification problem is:\n",
    "\n",
    "# Random forrest classifier model:\n",
    "\n",
    "rfc_f = RandomForestClassifier()\n",
    "rfc_f.fit(X_train_res,y_train_res) \n",
    "pred_train_rfc_f = rfc_f.predict(X_train_res)\n",
    "y_pred = rfc_f.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_rfc_f)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eea3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best random state for RandomForestClassifier model:\n",
    "\n",
    "maxAccu = 0\n",
    "maxRS = 0\n",
    "\n",
    "for i in range(1,200):\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(X_train_res,y_train_res) \n",
    "    y_pred = rfc.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Testing accuracy: ', acc, 'at random state', i)\n",
    "    \n",
    "    if acc > maxAccu:\n",
    "        maxAccu = acc\n",
    "        maxRS = i\n",
    "        print('Max accuracy',maxAccu,'max random state',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy: ',maxAccu,'at random state: ',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc91a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_f = RandomForestClassifier(random_state=66)\n",
    "rfc_f.fit(X_train_res,y_train_res) \n",
    "pred_train_rfc_f = rfc_f.predict(X_train_res)\n",
    "y_pred = rfc_f.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_rfc_f)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed00fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'n_estimators': [5,10,15,25,30,50,100],'criterion':['gini','entropy'], 'max_depth': [5,10,15,20,40,50,100], 'bootstrap': [True, False]}]\n",
    "\n",
    "grid_search_forest = GridSearchCV(rfc_f, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search_forest.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aca913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best model of grid search\n",
    "grid_search_forest.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c412da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_f = RandomForestClassifier(random_state=6)\n",
    "rfc_f.fit(X_train_res,y_train_res) \n",
    "pred_train_rfc_f = rfc_f.predict(X_train_res)\n",
    "y_pred = rfc_f.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_rfc_f)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4893e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in range(200,2000,200)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a27fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(random_state=6)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_rfc_ran = rf_random.predict(X_train_res)\n",
    "y_pred = rf_random.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_rfc_ran)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# GBC\n",
    "\n",
    "gbdt_clf = GradientBoostingClassifier(random_state=3)\n",
    "gbdt_clf.fit(X_train_res,y_train_res) \n",
    "pred_train_gbdt_clf = gbdt_clf.predict(X_train_res)\n",
    "y_pred = gbdt_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_gbdt_clf)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77811de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline:\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipecl = Pipeline([('pt',PowerTransformer()),('pca',PCA(n_components=800)),('base_model1',GradientBoostingClassifier(random_state=3))])\n",
    "\n",
    "pipecl.fit(X_train_res,y_train_res)\n",
    "\n",
    "y_predcl = pipecl.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_predcl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58127d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving regression model to pickle string\n",
    "\n",
    "import pickle \n",
    "saved_model1 = pickle.dumps(pipecl) \n",
    "pipe_pickle1 = pickle.loads(saved_model1)\n",
    "pipe_pickle1.predict(X_test) # predicting testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625b456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c3c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline:\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipereg = Pipeline([('pt',PowerTransformer()),('pca1',PCA(n_components=800)),('base_model2',xgb.XGBRegressor())])\n",
    "\n",
    "pipereg.fit(X_train_res,y_train_res)\n",
    "\n",
    "y_predreg = pipereg.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dffb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving regression model to pickle string\n",
    "\n",
    "import pickle \n",
    "saved_model2 = pickle.dumps(pipereg) \n",
    "pipe_pickle2 = pickle.loads(saved_model1)\n",
    "pipe_pickle1.predict(X_test) # predicting testing data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
