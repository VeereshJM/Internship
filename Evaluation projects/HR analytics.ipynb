{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "EXPLORATORY DATA ANALYSIS:\n",
    "\n",
    "1. HR attrition Dataset contains 1470 rows and 35 columns.\n",
    "\n",
    "2.    Basic info of columns are:\n",
    "\n",
    "        Data columns (total 35 columns):\n",
    "     #   Column                    Non-Null Count  Dtype \n",
    "    ---  ------                    --------------  ----- \n",
    "     0   Age                       1470 non-null   int64 \n",
    "     1   Attrition                 1470 non-null   object\n",
    "     2   BusinessTravel            1470 non-null   object\n",
    "     3   DailyRate                 1470 non-null   int64 \n",
    "     4   Department                1470 non-null   object\n",
    "     5   DistanceFromHome          1470 non-null   int64 \n",
    "     6   Education                 1470 non-null   int64 \n",
    "     7   EducationField            1470 non-null   object\n",
    "     8   EmployeeCount             1470 non-null   int64 \n",
    "     9   EmployeeNumber            1470 non-null   int64 \n",
    "     10  EnvironmentSatisfaction   1470 non-null   int64 \n",
    "     11  Gender                    1470 non-null   object\n",
    "     12  HourlyRate                1470 non-null   int64 \n",
    "     13  JobInvolvement            1470 non-null   int64 \n",
    "     14  JobLevel                  1470 non-null   int64 \n",
    "     15  JobRole                   1470 non-null   object\n",
    "     16  JobSatisfaction           1470 non-null   int64 \n",
    "     17  MaritalStatus             1470 non-null   object\n",
    "     18  MonthlyIncome             1470 non-null   int64 \n",
    "     19  MonthlyRate               1470 non-null   int64 \n",
    "     20  NumCompaniesWorked        1470 non-null   int64 \n",
    "     21  Over18                    1470 non-null   object\n",
    "     22  OverTime                  1470 non-null   object\n",
    "     23  PercentSalaryHike         1470 non-null   int64 \n",
    "     24  PerformanceRating         1470 non-null   int64 \n",
    "     25  RelationshipSatisfaction  1470 non-null   int64 \n",
    "     26  StandardHours             1470 non-null   int64 \n",
    "     27  StockOptionLevel          1470 non-null   int64 \n",
    "     28  TotalWorkingYears         1470 non-null   int64 \n",
    "     29  TrainingTimesLastYear     1470 non-null   int64 \n",
    "     30  WorkLifeBalance           1470 non-null   int64 \n",
    "     31  YearsAtCompany            1470 non-null   int64 \n",
    "     32  YearsInCurrentRole        1470 non-null   int64 \n",
    "     33  YearsSinceLastPromotion   1470 non-null   int64 \n",
    "     34  YearsWithCurrManager      1470 non-null   int64 \n",
    "     \n",
    "3. DATATYPES:\n",
    "            9 OUT OF 35 ARE CATEGORICAL COLUMNS NAMELY: \n",
    "            'Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender',\n",
    "            'JobRole', 'MaritalStatus', 'Over18', 'OverTime'\n",
    "            26 REMAINING COLUMNS ARE NUMERICAL.\n",
    "            \n",
    "4. No null values are there in dataset.\n",
    "\n",
    "\n",
    "5. No duplicates can be found in dataset.\n",
    "\n",
    "6. Understanding variables:\n",
    "\n",
    "By checking the attributes, we can see that some features are related to personal details of employees and others are\n",
    "professional details and data relevant to company and employee profile.\n",
    "\n",
    "personal_details = ['Age','DistanceFromHome', 'Education', 'EducationField','Gender',\n",
    "                    'MaritalStatus','RelationshipSatisfaction','Over18']\n",
    "\n",
    "\n",
    "personal_details_and_attrition = ['Age','DistanceFromHome', 'Education', 'EducationField','Gender',\n",
    "                    'MaritalStatus','RelationshipSatisfaction','Over18','Attrition']\n",
    "\n",
    "Thus we can analyse these features seperately.\n",
    "\n",
    "7. Descriptive statistics:\n",
    "\n",
    "We can note that standard deviation values of DailyRate , MonthlyIncome , MonthlyRate are high.\n",
    "\n",
    "Max value of EnvironmentSatisfaction is 4 and mean value is more than half. That means on an average basic sentiment of \n",
    "employees is that they feel average in terms of satisfaction.\n",
    "\n",
    "Job satisfaction value also signify that employees feel average in terms of satisfaction.\n",
    "\n",
    "For more than 75% employees job level is 3.\n",
    "\n",
    "PercentSalaryHike is also varrying where in min salary hike given is 11 percent wherein max salary hike is 25 percent.\n",
    "\n",
    "TotalWorkingYears feature has min value 0 and max value 40 that is varrying a lot.\n",
    "\n",
    "On an average, for WorkLifeBalance employee feel average about it .\n",
    "\n",
    "We can see in YearsAtCompany max value is 40 years and TotalWorkingYears years is also 40.\n",
    "For such a person who can stay in company for 40 years there might be some important factors influencing his employement duration.\n",
    "We can explore which features affect the employement duration the most.\n",
    "\n",
    "On an average, employee spend around 4.2 years in the current role but max value of YearsInCurrentRole is 18 and that is quite high.\n",
    "\n",
    "Even max values of YearsSinceLastPromotion and YearsWithCurrManager are very high and they indicate the presence of outliers.\n",
    "\n",
    "Most of employees stayed with the company with most attrition values being no,\n",
    "most of employees travel rarely, Research & Development, Life Sciences background, are male, are from Sales Executive job role\n",
    "are married and over 18 and prefer not doing overtime.\n",
    "\n",
    "For Attrition , most frequent value is:  ModeResult(mode=array(['No'], dtype=object), count=array([1233]))\n",
    "For BusinessTravel , most frequent value is:  ModeResult(mode=array(['Travel_Rarely'], dtype=object), count=array([1043]))\n",
    "For Department , most frequent value is:  ModeResult(mode=array(['Research & Development'], dtype=object), count=array([961]))\n",
    "For EducationField , most frequent value is:  ModeResult(mode=array(['Life Sciences'], dtype=object), count=array([606]))\n",
    "For Gender , most frequent value is:  ModeResult(mode=array(['Male'], dtype=object), count=array([882]))\n",
    "For JobRole , most frequent value is:  ModeResult(mode=array(['Sales Executive'], dtype=object), count=array([326]))\n",
    "For MaritalStatus , most frequent value is:  ModeResult(mode=array(['Married'], dtype=object), count=array([673]))\n",
    "For Over18 , most frequent value is:  ModeResult(mode=array(['Y'], dtype=object), count=array([1470]))\n",
    "For OverTime , most frequent value is:  ModeResult(mode=array(['No'], dtype=object), count=array([1054]))\n",
    "\n",
    "8. Exploring unique value counts of categorical variables :\n",
    "\n",
    "For column Attrition unique values are:  ['Yes' 'No']\n",
    "For column Attrition count of unique values are:  2 \n",
    "\n",
    "\n",
    "For column BusinessTravel unique values are:  ['Travel_Rarely' 'Travel_Frequently' 'Non-Travel']\n",
    "For column BusinessTravel count of unique values are:  3 \n",
    "\n",
    "\n",
    "For column Department unique values are:  ['Sales' 'Research & Development' 'Human Resources']\n",
    "For column Department count of unique values are:  3 \n",
    "\n",
    "\n",
    "For column EducationField unique values are:  ['Life Sciences' 'Other' 'Medical' 'Marketing' 'Technical Degree'\n",
    " 'Human Resources']\n",
    "For column EducationField count of unique values are:  6 \n",
    "\n",
    "\n",
    "For column Gender unique values are:  ['Female' 'Male']\n",
    "For column Gender count of unique values are:  2 \n",
    "\n",
    "\n",
    "For column JobRole unique values are:  ['Sales Executive' 'Research Scientist' 'Laboratory Technician'\n",
    " 'Manufacturing Director' 'Healthcare Representative' 'Manager'\n",
    " 'Sales Representative' 'Research Director' 'Human Resources']\n",
    "For column JobRole count of unique values are:  9 \n",
    "\n",
    "\n",
    "For column MaritalStatus unique values are:  ['Single' 'Married' 'Divorced']\n",
    "For column MaritalStatus count of unique values are:  3 \n",
    "\n",
    "\n",
    "For column Over18 unique values are:  ['Y']\n",
    "For column Over18 count of unique values are:  1 \n",
    "\n",
    "\n",
    "For column OverTime unique values are:  ['Yes' 'No']\n",
    "For column OverTime count of unique values are:  2 \n",
    "\n",
    "9. For column -- Attrition -- value counts are: \n",
    " No     1233\n",
    "Yes     237\n",
    "\n",
    "\n",
    "For column -- BusinessTravel -- value counts are: \n",
    " Travel_Rarely        1043\n",
    "Travel_Frequently     277\n",
    "Non-Travel            150\n",
    "\n",
    "\n",
    "For column -- Department -- value counts are: \n",
    " Research & Development    961\n",
    "Sales                     446\n",
    "Human Resources            63\n",
    "\n",
    "\n",
    "For column -- EducationField -- value counts are: \n",
    " Life Sciences       606\n",
    "Medical             464\n",
    "Marketing           159\n",
    "Technical Degree    132\n",
    "Other                82\n",
    "Human Resources      27\n",
    "\n",
    "\n",
    "For column -- Gender -- value counts are: \n",
    " Male      882\n",
    "Female    588\n",
    "\n",
    "\n",
    "For column -- JobRole -- value counts are: \n",
    " Sales Executive              326\n",
    "Research Scientist           292\n",
    "Laboratory Technician        259\n",
    "Manufacturing Director       145\n",
    "Healthcare Representative    131\n",
    "Manager                      102\n",
    "Sales Representative          83\n",
    "Research Director             80\n",
    "Human Resources               52\n",
    "\n",
    "\n",
    "For column -- MaritalStatus -- value counts are: \n",
    " Married     673\n",
    "Single      470\n",
    "Divorced    327\n",
    "\n",
    "\n",
    "For column -- Over18 -- value counts are: \n",
    " Y    1470\n",
    "\n",
    "\n",
    "For column -- OverTime -- value counts are: \n",
    " No     1054\n",
    "Yes     416\n",
    "\n",
    "10. Univariate analysis:\n",
    "\n",
    "        Using histogram peak frequencies of features are indicated below:\n",
    "\n",
    "        Age: (25,45)\n",
    "\n",
    "        Dailyrate (100,1500)\n",
    "\n",
    "        Fordistance from home (Within 10-12)\n",
    "\n",
    "        Education rating 3 has highest frequency.\n",
    "\n",
    "        For relationship satisfaction, environment satisfaction, highest frequency are of 3 and 4.\n",
    "\n",
    "        Hourly rate is uniform throughout.\n",
    "\n",
    "        Max and min value of jobinvolvement is 1 and 3 for worklife balance.\n",
    "\n",
    "        1 and 2 have highest frequency in job level and  0 and 1 for stock option level.\n",
    "\n",
    "        3 and 4have highest frequency in job satisfaction.\n",
    "\n",
    "        Monthly income, most freq lie btw 1500 to 7500.\n",
    "\n",
    "        Mostly people have worked in 1-2 companies.\n",
    "\n",
    "        Mostly people got salary hike btw 10-15 percent.\n",
    "\n",
    "        Mostly people got 3 as performance rating.\n",
    "        Mostly employees have working hours ranging btw 0-15.\n",
    "\n",
    "        Total working years (5,10)\n",
    "\n",
    "        Training times last year (2,3 and 4)\n",
    "\n",
    "        Mostly employees stayed 0,15 years in the company.\n",
    "\n",
    "        Mostly employees stayed 2.5 years in the current role and 0-2 years since last promotion and 0-5 years with current manager.\n",
    "\n",
    "11. Bivariate analysis:\n",
    "\n",
    "    Scatterplot:\n",
    "    \n",
    "    We can say that high aged employees above 50 age tend to stay with company and said no to attrition.\n",
    "    \n",
    "    Buisness travel,Daily rate, department, distance from home,education and field, cant confirm any trend in attrition.\n",
    "    \n",
    "12. Multivariate analysis using scatterplot and hues:\n",
    "\n",
    "    Employees having education level upto 3 and of less age < 40 tend tend to leave company early.\n",
    "    \n",
    "    Emp getting salary hike < 12-20 % and of less age, some outliers getting 25 % hike,\n",
    "    \n",
    "    Employees having job envolvement less that 3, salary < 8000-12000, \n",
    "    having technical , lifesciences, marketting background and who have to travel,\n",
    "    \n",
    "    are mainly contributing in positive attrition.\n",
    "    \n",
    "13. Data distribution:\n",
    "\n",
    "Monthly income, distance from home, num companies worked, percent salary hike, total working hours, years at company,\n",
    "years in current role, years since last promotion, years with cur. manager have skewed graphs that reflect presence of outliers.\n",
    "\n",
    "14. Multivariate analysis using regression line plot:\n",
    "\n",
    "There is no proper relation between attrition btw RelationshipSatisfaction and PerformanceRating, DistanceFromHome and age,\n",
    "age and years at company show +ive relation with attrition, also years at company and last promotion, eyars with manager \n",
    ", current tole, monthly income show +live relation with attrition.\n",
    "\n",
    "\n",
    "15. Presence of outliers:MonthlyIncome,NumCompaniesWorked,PerformanceRating,StockOptionLevel,TotalWorkingYears,\n",
    "TrainingTimesLastYear,'YearsAtCompany', 'YearsInCurrentRole','YearsSinceLastPromotion', 'YearsWithCurrManager'\n",
    "\n",
    "16. Checking skewness in data: \n",
    "\n",
    "JobLevel                    1.025401\n",
    "NumCompaniesWorked          1.026471\n",
    "TotalWorkingYears           1.117172\n",
    "MonthlyIncome               1.369817\n",
    "YearsAtCompany              1.764529\n",
    "PerformanceRating           1.921883\n",
    "YearsSinceLastPromotion     1.984290\n",
    "\n",
    "represent skewness values and data can be seen slightly skewed and we can use outlier removal techniques to treat outliers.\n",
    "\n",
    "18. Pairplot analysis : +ive and -ive trends can be seen in dataset.\n",
    "\n",
    "19. Checking correlation:\n",
    "    \n",
    "    Negative correlation:\n",
    "\n",
    "       'Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
    "       , 'Education', 'EducationField', 'EmployeeCount',\n",
    "       'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate',\n",
    "       'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n",
    "       'MaritalStatus',  'MonthlyIncome', 'NumCompaniesWorked',\n",
    "       'Over18', 'OverTime', 'PerformanceRating',\n",
    "       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager'\n",
    "       \n",
    "    Positive correlation:DistanceFromHome , MonthlyRate , PercentSalaryHike\n",
    "    \n",
    "    Most features can be seen to be -ively correlated.\n",
    "    \n",
    "    It seems perfornamce rating monthly rate, salary hike and distance are major features responsible for attrition.\n",
    "    \n",
    "20.Analysing heat map:\n",
    "\n",
    "multicollinearity problem can be seen between job level , monthly income , %salary hike and rating, \n",
    "'YearsInCurrentRole', 'YearsSinceLastPromotion','YearsWithCurrManager'\n",
    "\n",
    "21. Using zcore to remove outliers, we are removed 5.64 percent outliers and 83 in numbers.\n",
    "\n",
    "22. VIF confirms presence of multicollinearity.\n",
    "\n",
    "23. Furthur steps:\n",
    "\n",
    "multicollinearity treatment.\n",
    "power transformation.\n",
    "Principal component analysis: selecting most important 35 features.\n",
    "Using oversampling technique to treat imbalanced dataset.\n",
    "\n",
    "24. Model making: we have used:\n",
    "\n",
    "logistic regression\n",
    "decision tree clasifier\n",
    "SVC , Random forest classifier\n",
    "knn classifier\n",
    "gradient boosting classifier\n",
    "ada boost classifier\n",
    "naive bayes classifier.\n",
    "\n",
    "25. Final results: Using logistic regression model, we have found best random state, used gridsearch cv and randomised search cv\n",
    "    to find best results and accuracy that we have cross checked using auc roc curve:\n",
    "    \n",
    "    results are :\n",
    "    \n",
    "    tuned hpyerparameters :(best parameters)  {'C': 0.1, 'penalty': 'l2'}\n",
    "    accuracy : 0.8319415688980907\n",
    "    \n",
    "    Confusion matrix: \n",
    "         [[269  80]\n",
    "         [ 17  51]]\n",
    "        classification report:                precision    recall  f1-score   support\n",
    "\n",
    "                   0       0.94      0.77      0.85       349\n",
    "                   1       0.39      0.75      0.51        68\n",
    "\n",
    "            accuracy                           0.77       417\n",
    "           macro avg       0.66      0.76      0.68       417\n",
    "        weighted avg       0.85      0.77      0.79       417\n",
    "        \n",
    "\n",
    "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
    "RandomizedSearchCV(estimator=LogisticRegression(random_state=1), n_iter=100,\n",
    "                   n_jobs=-1,\n",
    "                   param_distributions={'C': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
    "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
    "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
    "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
    "       0.44, 0.45, 0.46, 0.47...\n",
    "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
    "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
    "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
    "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
    "       0.99]),\n",
    "                                        'max_iter': range(100, 500),\n",
    "                                        'solver': ['lbfgs', 'newton-cg',\n",
    "                                                   'liblinear'],\n",
    "                                        'warm_start': [True, False]},\n",
    "                   random_state=1, scoring='accuracy', verbose=1)\n",
    "\n",
    "AUC score: 0.7603868194842407\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imp libs:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Standardizing and Normalizing data:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Spliting data\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Importing metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80161bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = r'C:\\Users\\User\\Downloads\\ibm-hr-analytics-employee-attrition-performance.zip'\n",
    "df = pd.read_csv(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77510680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting option to show max rows and max columns\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7562cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72743314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_data = df.select_dtypes(include=['int64','float64'])\n",
    "\n",
    "cat_data= df.select_dtypes(include=['object'])\n",
    "\n",
    "cont_columns = cont_data.columns\n",
    "\n",
    "cat_columns = cat_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b343e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cont_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf74b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8513ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99abeddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = df[df.duplicated()]\n",
    "dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e44b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bdc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e856ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: \n",
    "\n",
    "personal_details = ['Age','DistanceFromHome', 'Education', 'EducationField','Gender',\n",
    "                    'MaritalStatus','RelationshipSatisfaction','Over18']\n",
    "\n",
    "\n",
    "personal_details_and_attrition = ['Age','DistanceFromHome', 'Education', 'EducationField','Gender',\n",
    "                    'MaritalStatus','RelationshipSatisfaction','Over18','Attrition']\n",
    "\n",
    "company_parameters = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if i not in personal_details:\n",
    "        company_parameters.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f620b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(company_parameters) + len(personal_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c458d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personal = df[personal_details_and_attrition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aff5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf28781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_professional = df[company_parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_professional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a9fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb666928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9204c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_columns:\n",
    "    print('For column',i,'unique values are: ',df[i].unique())\n",
    "    print('For column',i,'count of unique values are: ',df[i].nunique(),'\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c35e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for i in cat_columns:\n",
    "    print('For',i,', most frequent value is: ',stats.mode(df[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_columns:\n",
    "    print('For column --',i,'-- value counts are: \\n',df[i].value_counts(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "by = 'Attrition'\n",
    "df_personal.groupby(by).apply(lambda a:a.drop(by,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts in Categorical variables:\n",
    "\n",
    "for i in cat_columns:\n",
    "    print(df[i].value_counts())\n",
    "    plt.figure(figsize=(10,6),facecolor='orange')\n",
    "    df[i].value_counts().plot(kind='bar')\n",
    "    plt.title('Value counts of categorical variables')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    print(i,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f006b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot:\n",
    "\n",
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(10,6),facecolor='orange')\n",
    "    plt.hist(df[i],bins=10)\n",
    "    plt.xlabel(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot between columns and attrition:\n",
    "\n",
    "for i in df.columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.scatterplot(x='Attrition',y=df[i],data=df,hue='Education')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe98937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot between columns and attrition:\n",
    "\n",
    "for i in df.columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.scatterplot(x='Attrition',y=df[i],data=df,hue='PercentSalaryHike')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot between columns and attrition:\n",
    "\n",
    "for i in df.columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.scatterplot(x='Attrition',y=df[i],data=df,hue='JobInvolvement')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot between columns and attrition:\n",
    "\n",
    "for i in df.columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.scatterplot(x='Attrition',y=df[i],data=df,hue='MonthlyIncome')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11578747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot between columns and attrition:\n",
    "\n",
    "for i in df.columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.scatterplot(x='Attrition',y=df[i],data=df,hue='EducationField')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of continuous variables:\n",
    "\n",
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.distplot(df[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87af680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lm plot to check reg: \n",
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"PerformanceRating\", y = \"RelationshipSatisfaction\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f75654",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Age\", y = \"DistanceFromHome\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12644edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa321515",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Age\", y = \"EnvironmentSatisfaction\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b88778",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Age\", y = \"YearsAtCompany\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253022d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Age\", y = \"YearsInCurrentRole\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf499c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Age\", y = \"WorkLifeBalance\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Age\", y = \"TrainingTimesLastYear\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08773364",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"YearsAtCompany\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b01cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"YearsInCurrentRole\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"YearsWithCurrManager\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56554be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"PercentSalaryHike\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"MonthlyIncome\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00bc036",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"JobLevel\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d50694",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"JobInvolvement\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6490a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"HourlyRate\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"EnvironmentSatisfaction\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"EmployeeNumber\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12809fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Education\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5926056",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"DistanceFromHome\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef77acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"DailyRate\", y = \"YearsSinceLastPromotion\", data=df, hue='Attrition', palette='Set2', height=8, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29616abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603cf7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the outliers in continuous variables:\n",
    "\n",
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.boxplot(df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e585571",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb1a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c902160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features and label:\n",
    "\n",
    "# Replacing attrition column values:\n",
    "df['Attrition'].replace(['Yes','No'],[1,0],inplace=True)\n",
    "\n",
    "df.drop(columns = 'Attrition',axis = 1).corrwith(df.Attrition).plot(kind='bar',grid=True,figsize=(10,7),title='corelation between features and labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation (personal) between features and label:\n",
    "\n",
    "df_personal.drop(columns = 'Attrition',axis = 1).corrwith(df.Attrition).plot(kind='bar',grid=True,figsize=(10,7),title='corelation between features and labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e2aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation (personal) between features and label:\n",
    "\n",
    "df_professional.drop(columns = 'Attrition',axis = 1).corrwith(df.Attrition).plot(kind='bar',grid=True,figsize=(10,7),title='corelation between features and labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr().abs()\n",
    "plt.figure(figsize=(25,22))\n",
    "sns.heatmap(df_corr,annot=True,annot_kws={'size':10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Z Statistics to check and remove any more outliers:\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "outlier_cols = ['YearsWithCurrManager','YearsSinceLastPromotion','YearsInCurrentRole',\n",
    "'YearsAtCompany','TrainingTimesLastYear','TotalWorkingYears','StockOptionLevel','PerformanceRating',\n",
    "'NumCompaniesWorked','MonthlyIncome']\n",
    "\n",
    "z_score = zscore(df[outlier_cols])\n",
    "\n",
    "abs_z_score = np.abs(z_score)\n",
    "\n",
    "filtering_entry = (abs_z_score < 3).all(axis=1) # values lying in 3 times std will be removed\n",
    "\n",
    "df = df[filtering_entry]\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1470-1387 # 83 Outliers removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "83/1470*100 # Percentage of outliers in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb73ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['vif'] = [variance_inflation_factor(df[cont_columns],i) for i in range(df[cont_columns].shape[1])]\n",
    "vif['features'] = df[cont_columns].columns\n",
    "vif\n",
    "\n",
    "# These number indicate that if vif value < 5 , \n",
    "# no multicolinearity problem exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['JobLevel'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65790fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015cf13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd789370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WorkLifeBalance            -0.552480\n",
    "JobInvolvement             -0.498419\n",
    "JobSatisfaction            -0.329672\n",
    "EnvironmentSatisfaction    -0.321654\n",
    "RelationshipSatisfaction   -0.302828\n",
    "Education                  -0.289681\n",
    "HourlyRate                 -0.032311\n",
    "DailyRate                  -0.003519\n",
    "EmployeeCount               0.000000\n",
    "StandardHours               0.000000\n",
    "EmployeeNumber              0.016574\n",
    "MonthlyRate                 0.018578\n",
    "Age                         0.413286\n",
    "TrainingTimesLastYear       0.553124\n",
    "PercentSalaryHike           0.821128\n",
    "YearsWithCurrManager        0.833451\n",
    "YearsInCurrentRole          0.917363\n",
    "DistanceFromHome            0.958118\n",
    "StockOptionLevel            0.968980\n",
    "JobLevel                    1.025401\n",
    "NumCompaniesWorked          1.026471\n",
    "TotalWorkingYears           1.117172\n",
    "MonthlyIncome               1.369817\n",
    "YearsAtCompany              1.764529\n",
    "PerformanceRating           1.921883\n",
    "YearsSinceLastPromotion     1.984290\n",
    "dtype: float64\"\"\"\n",
    "\n",
    "df_new.skew().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fe8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "data_trans = pt.fit_transform(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75796c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of continuous variables:\n",
    "\n",
    "sns.distplot(data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20155eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and label:\n",
    "\n",
    "y = df_new['Attrition']\n",
    "X = df_new.drop('Attrition',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78da4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "X_trans = pt.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7426cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Using PCA i.e. Principal Component Analysis that is a diamensionallity reduction technique:\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit_transform(X_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scree Plot to identify best components:\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Covered')\n",
    "plt.title('PCA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=35)\n",
    "new_pcomp = pca.fit_transform(X_trans)\n",
    "princi_comp = pd.DataFrame(new_pcomp,columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7',\n",
    "                                              'PC8','PC9','PC10','PC11','PC12','PC13','PC14',\n",
    "                                              'PC15','PC16','PC17','PC18','PC19','PC20', \n",
    "                                              'PC21','PC22','PC23','PC24','PC25','PC26','PC27',\n",
    "                                              'PC28','PC29','PC30','PC31','PC32','PC33','PC34',\n",
    "                                              'PC35'])\n",
    "princi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "princi_comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(princi_comp, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805eda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(y_train_res)\n",
    "\n",
    "un, co = np.unique(arr,return_counts=True)\n",
    "\n",
    "dict(zip(un,co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51987c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best random state for logistic regression model:\n",
    "\n",
    "maxAccu = 0\n",
    "maxRS = 0\n",
    "\n",
    "for i in range(1,200):\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train_res,y_train_res) \n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Testing accuracy: ', acc, 'at random state', i)\n",
    "    \n",
    "    if acc > maxAccu:\n",
    "        maxAccu = acc\n",
    "        maxRS = i\n",
    "        print('Max accuracy',maxAccu,'max random state',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2710935",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy: ',maxAccu,'at random state: ',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464acab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression:\n",
    "\n",
    "log_reg = LogisticRegression(random_state=1)\n",
    "\n",
    "log_reg.fit(X_train_res,y_train_res) \n",
    "\n",
    "pred_train = log_reg.predict(X_train_res)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "\n",
    "clr = classification_report(y_test,y_pred)\n",
    "\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot ROC AUC curve to choose best model:\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33888350",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_roc_curve(log_reg,X_train_res,y_train_res)\n",
    "\n",
    "plot_roc_curve(log_reg,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':10},loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5bfa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best random state for :Decision tree classifier\n",
    "\n",
    "maxdtcrs = 0\n",
    "maxRS = 0\n",
    "\n",
    "for i in range(1,200):\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train_res,y_train_res) \n",
    "    pred_train_dtc = dtc.predict(X_train_res)\n",
    "    y_pred = dtc.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Training accuracy: ', accuracy_score(y_train_res,pred_train_dtc)*100)\n",
    "    print('Testing accuracy: ', acc*100)\n",
    "    \n",
    "    if acc > maxdtcrs:\n",
    "        maxdtcrs = acc\n",
    "        maxRSdtc = i\n",
    "        print('Max accuracy',maxdtcrs,'max random state',maxRSdtc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b714a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy: ',maxdtcrs,'at random state: ',maxRSdtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025a3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best result for Decision Tree Classifier:\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=66)\n",
    "dtc.fit(X_train_res,y_train_res) \n",
    "pred_train_dtc = dtc.predict(X_train_res)\n",
    "y_pred = dtc.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_dtc)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7027831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER PARAMETER TUNING for DTC:\n",
    "\n",
    "# Tuning parameters using GridSearchCV:\n",
    "\n",
    "params = {'criterion':['gini','entrophy'],'max_depth':range(0,20)} # at which rate our model should learn\n",
    "\n",
    "grd_dtc = GridSearchCV(dtc,param_grid=params)\n",
    "\n",
    "grd_dtc.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f03bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_dtc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_f = DecisionTreeClassifier(criterion = 'gini',  max_depth = 18,random_state=124)\n",
    "dtc_f.fit(X_train_res,y_train_res) \n",
    "pred_train_dtc_f = dtc.predict(X_train_res)\n",
    "y_pred = dtc_f.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_dtc_f)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8fe2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_roc_curve(dtc_f,X_train_res,y_train_res)\n",
    "\n",
    "plot_roc_curve(dtc_f,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':10},loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c081dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best random state for Random Forest Classifier:\n",
    "\n",
    "maxRFAccu = 0\n",
    "maxRFRS = 0\n",
    "\n",
    "for i in range(1,200):\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(X_train_res,y_train_res) \n",
    "    pred_train_rfc = rfc.predict(X_train_res)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Training accuracy: ', accuracy_score(y_train_res,pred_train_rfc)*100)\n",
    "    print('Testing accuracy: ', acc*100)\n",
    "    \n",
    "    if acc > maxRFAccu:\n",
    "        maxRFAccu = acc\n",
    "        maxRFRS = i\n",
    "        print('Max accuracy',maxRFAccu,'max random state',maxRFRS)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy: ',maxRFAccu,'at random state: ',maxRFRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c29e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER PARAMETER TUNING for DTC:\n",
    "\n",
    "# Tuning parameters using GridSearchCV:\n",
    "\n",
    "params = {'criterion':['gini','entrophy'],'max_depth':range(0,20)} # at which rate our model should learn\n",
    "\n",
    "grd_rf = GridSearchCV(rfc,param_grid=params)\n",
    "\n",
    "grd_rf.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d8da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_f = RandomForestClassifier(random_state=182,criterion='gini',max_depth=18)\n",
    "rfc_f.fit(X_train_res,y_train_res) \n",
    "pred_train_rfc_f = rfc.predict(X_train_res)\n",
    "y_pred = rfc_f.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_rfc)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fba769",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_roc_curve(rfc_f,X_train_res,y_train_res)\n",
    "\n",
    "plot_roc_curve(rfc_f,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':10},loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb087265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best random state for SVC:\n",
    "\n",
    "maxsAccu = 0\n",
    "maxsRS = 0\n",
    "\n",
    "for i in range(1,200):\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_res,y_train_res) \n",
    "    pred_train_svc = svc.predict(X_train_res)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Training accuracy: ', accuracy_score(y_train_res,pred_train_svc)*100)\n",
    "    print('Testing accuracy: ', acc*100)\n",
    "    \n",
    "    if acc > maxAccu:\n",
    "        maxsAccu = acc\n",
    "        maxsRS = i\n",
    "        print('Max accuracy',maxsAccu,'max random state',maxsRS)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameter Tuning in SVM and finding best parameters:\n",
    "\n",
    "param_grid = {'C':[1,5,10,20],'gamma':[0.001,0.01,0.02,0.002]}\n",
    "\n",
    "grds = GridSearchCV(svc,param_grid)\n",
    "\n",
    "grds.fit(X_train_res,y_train_res)\n",
    "\n",
    "grds.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using best parameters for improved score:\n",
    "\n",
    "svc = SVC(C=20,gamma=0.02,random_state=1)\n",
    "\n",
    "svc.fit(X_train_res,y_train_res)\n",
    "\n",
    "pred_train_svc = svc.predict(X_train_res)\n",
    "y_pred = svc.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_svc)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_roc_curve(svc,X_train_res,y_train_res)\n",
    "\n",
    "plot_roc_curve(svc,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':10},loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best random state for KNN:\n",
    "\n",
    "maxAccu = 0\n",
    "maxRS = 0\n",
    "\n",
    "for i in range(1,200):\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train_res,y_train_res) \n",
    "    pred_train_knn = knn.predict(X_train_res)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Training accuracy: ', accuracy_score(y_train_res,pred_train_knn)*100)\n",
    "    print('Testing accuracy: ', acc*100)\n",
    "    \n",
    "    if acc > maxAccu:\n",
    "        maxAccu = acc\n",
    "        maxRS = i\n",
    "        print('Max accuracy',maxAccu,'max random state',maxRS)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4411345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Finding best random state for GBDTC:\n",
    "\n",
    "maxAccu = 0\n",
    "maxRS = 0\n",
    "\n",
    "for i in range(1,200):\n",
    "    gbdt_clf = GradientBoostingClassifier()\n",
    "    gbdt_clf.fit(X_train_res,y_train_res) \n",
    "    pred_train_gbdt_clf = gbdt_clf.predict(X_train_res)\n",
    "    y_pred = gbdt_clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Training accuracy: ', accuracy_score(y_train_res,pred_train_gbdt_clf)*100)\n",
    "    print('Testing accuracy: ', acc*100)\n",
    "    \n",
    "    if acc > maxAccu:\n",
    "        maxAccu = acc\n",
    "        maxRS = i\n",
    "        print('Max accuracy',maxAccu,'max random state',maxRS)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3917921",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy: ',maxAccu,'at random state: ',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_clf = GradientBoostingClassifier(random_state=3)\n",
    "gbdt_clf.fit(X_train_res,y_train_res) \n",
    "pred_train_gbdt_clf = gbdt_clf.predict(X_train_res)\n",
    "y_pred = gbdt_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_gbdt_clf)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b83c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER PARAMETER TUNING:\n",
    "\n",
    "# Tuning parameters using GridSearchCV:\n",
    "\n",
    "params = {'max_depth':range(4,8),\n",
    "          'min_samples_split':range(2,8,2),\n",
    "          'learning_rate':np.arange(0.1,0.3)} # at which rate our model should learn\n",
    "\n",
    "grd = GridSearchCV(gbdt_clf,param_grid=params)\n",
    "\n",
    "grd.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18756447",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc670d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating gradient boosting classifier:\n",
    "\n",
    "gbdt_clf_f = GradientBoostingClassifier(learning_rate=0.1, max_depth=7, min_samples_split=2)\n",
    "\n",
    "# Training the model\n",
    "gbdt_clf_f.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afe724",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_gbdt_clf_f = gbdt_clf_f.predict(X_train_res)\n",
    "y_pred = gbdt_clf_f.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_gbdt_clf_f)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab865fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_roc_curve(gbdt_clf_f,X_train_res,y_train_res)\n",
    "\n",
    "plot_roc_curve(gbdt_clf_f,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':10},loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a460f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ada boost model:\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Finding best random state for GBDTC:\n",
    "\n",
    "maxAccu = 0\n",
    "maxRS = 0\n",
    "\n",
    "for i in range(1,200):\n",
    "    ada = AdaBoostClassifier()\n",
    "    ada.fit(X_train_res,y_train_res)\n",
    "    y_pred = ada.predict(X_test)\n",
    "    pred_train_ada = ada.predict(X_train_res)\n",
    "    y_pred = ada.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Training accuracy: ', accuracy_score(y_train_res,pred_train_ada)*100)\n",
    "    print('Testing accuracy: ', acc*100)\n",
    "    \n",
    "    if acc > maxAccu:\n",
    "        maxAccu = acc\n",
    "        maxRS = i\n",
    "        print('Max accuracy',maxAccu,'max random state',maxRS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d88dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy: ',maxAccu,'at random state: ',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameter tuning using Randomised Search CV :\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {'n_estimators':[47,50,60,70],'learning_rate':[0.25,0.3,0.4]}\n",
    "\n",
    "rnd = RandomizedSearchCV(ada,param_distributions=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ede9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996cbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boosted = AdaBoostClassifier(learning_rate=0.4, n_estimators=70,random_state=1)\n",
    "ada_boosted.fit(X_train_res,y_train_res)\n",
    "yb_pred = ada_boosted.predict(X_test)\n",
    "pred_train_ada = ada.predict(X_train_res)\n",
    "y_pred = ada.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_ada)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_roc_curve(ada_boosted,X_train_res,y_train_res)\n",
    "\n",
    "plot_roc_curve(ada_boosted,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':10},loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80fbc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check ROC AUC Curve for fitted models on training data: (True +ive Rate/False +ive Rate)\n",
    "\n",
    "disp = plot_roc_curve(dtc,X_train_res,y_train_res)\n",
    "\n",
    "plot_roc_curve(knn,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(log_reg,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(svc,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(rfc,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(ada_boosted,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(gbdt_clf_f,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':10},loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# This result is on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check ROC AUC Curve for fitted models on testing data: (True +ive Rate/False +ive Rate)\n",
    "\n",
    "disp = plot_roc_curve(dtc,X_test,y_test)\n",
    "\n",
    "plot_roc_curve(knn,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(log_reg,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(svc,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(rfc,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(ada,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(gbdt_clf_f,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':10},loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# This result is on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do further hyper parameter tuning with logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression:\n",
    "\n",
    "log_reg = LogisticRegression(random_state=1)\n",
    "\n",
    "log_reg.fit(X_train_res,y_train_res) \n",
    "\n",
    "pred_train = log_reg.predict(X_train_res)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "\n",
    "clr = classification_report(y_test,y_pred)\n",
    "\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bcc28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV:\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg_cv=GridSearchCV(log_reg,grid,cv=10)\n",
    "logreg_cv.fit(X_train_res,y_train_res)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642df09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2=LogisticRegression(C=0.1,penalty=\"l2\")\n",
    "logreg2.fit(X_train_res,y_train_res)\n",
    "print(\"score\",logreg2.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac05004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomisedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bb783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "max_iter = range(100, 500)\n",
    "solver = ['lbfgs', 'newton-cg', 'liblinear']\n",
    "warm_start = [True, False]\n",
    "C = np.arange(0, 1, 0.01)\n",
    "random_grid ={\n",
    "    'max_iter' : max_iter,\n",
    "    'warm_start' : warm_start,\n",
    "    'solver' : solver,\n",
    "    'C' : C,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_estimator = RandomizedSearchCV(estimator = log_reg,\n",
    "                                   param_distributions = random_grid,\n",
    "                                   n_iter = 100,\n",
    "                                   scoring = 'accuracy',\n",
    "                                   n_jobs = -1,\n",
    "                                   verbose = 1, \n",
    "                                   random_state = 1,\n",
    "                                  )\n",
    "\n",
    "random_estimator.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7640a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_estimator.best_params_\n",
    "\n",
    "best_estimator = random_estimator.best_estimator_\n",
    "\n",
    "best_estimator.fit(X_train_res,y_train_res)\n",
    "\n",
    "pred = best_estimator.predict(X_test)\n",
    "\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32150967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "predicted = log_reg.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(accuracy_score(y_test,predicted)))\n",
    "print(\"Cohen Kappa score: {:.2f}\".format(cohen_kappa_score(y_test,predicted)))\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = sns.heatmap(confusion_matrix(y_test,predicted),annot=True)\n",
    "ax = ax.set(xlabel='Predicted',ylabel='True',title='Confusion Matrix',\n",
    "            xticklabels=(['True', 'False']),\n",
    "            yticklabels=(['True', 'False']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roc curve will give true +ive rate , false pr and threshold:\n",
    "\n",
    "fpr,tpr,threshold = roc_curve(y_test,predicted)\n",
    "print(fpr,'\\t',tpr,'\\t',threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8bb5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr,tpr,color='orange',label='ROC')\n",
    "plt.plot([0,1],[0,1],color='blue', linestyle = '--')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('Reciever operating characteristics (ROC) curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d56811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much area it is covering:\n",
    "auc_score = roc_auc_score(y_test,predicted)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498fc693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline:\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([(pt,PowerTransformer()),('pca',PCA(n_components=35)),('log_reg',RandomizedSearchCV(estimator = log_reg,param_distributions = random_grid,\n",
    "                                                           n_iter = 100,scoring = 'accuracy',\n",
    "                                                           n_jobs = -1,verbose = 1,random_state = 1))])\n",
    "\n",
    "pipe.fit(X_train_res,y_train_res)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model to pickle string\n",
    "\n",
    "import pickle \n",
    "saved_model = pickle.dumps(pipe) \n",
    "pipe_pickle = pickle.loads(saved_model)\n",
    "pipe_pickle.predict(X_test) # predicting testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd6430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
