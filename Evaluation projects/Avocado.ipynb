{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd217f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset Exploratory data analysis AND FURTHUR STEPS:\n",
    "\n",
    "Elementary exploration and definitions:\n",
    "\n",
    "1.Dataset contains 18249 rows and 13 columns including target label i.e. 'AveragePrice' for regresison problem and \n",
    "  region for 'classification' problem.\n",
    "  \n",
    "2. From dataset information: \n",
    "\n",
    " 0   Date          18249 non-null  object \n",
    " 1   AveragePrice  18249 non-null  float64\n",
    " 2   Total Volume  18249 non-null  float64\n",
    " 3   4046          18249 non-null  float64\n",
    " 4   4225          18249 non-null  float64\n",
    " 5   4770          18249 non-null  float64\n",
    " 6   Total Bags    18249 non-null  float64\n",
    " 7   Small Bags    18249 non-null  float64\n",
    " 8   Large Bags    18249 non-null  float64\n",
    " 9   XLarge Bags   18249 non-null  float64\n",
    " 10  type          18249 non-null  object \n",
    " 11  year          18249 non-null  int64  \n",
    " 12  region        18249 non-null  object \n",
    " \n",
    "Date, type, region are categorical data types and rest are numerical columns.\n",
    "\n",
    "3. No null values are present in dataset.\n",
    "\n",
    "4. Descriptive statistics of dataset:\n",
    "    Data summary:\n",
    "        Numerical columns:\n",
    "                Total counts in each rows are: 18249\n",
    "                Max min mean and range ie. max-min of each column are represented below:\n",
    "                \n",
    "                                    min\tmean\tmax\trange\n",
    "                AveragePrice\t0.44\t1.405978\t3.25\t2.81\n",
    "                Total Volume\t84.56\t850644.013009\t62505646.52\t62505561.96\n",
    "                4046\t0.00\t293008.424531\t22743616.17\t22743616.17\n",
    "                4225\t0.00\t295154.568356\t20470572.61\t20470572.61\n",
    "                4770\t0.00\t22839.735993\t2546439.11\t2546439.11\n",
    "                Total Bags\t0.00\t239639.202060\t19373134.37\t19373134.37\n",
    "                Small Bags\t0.00\t182194.686696\t13384586.80\t13384586.80\n",
    "                Large Bags\t0.00\t54338.088145\t5719096.61\t5719096.61\n",
    "                XLarge Bags\t0.00\t3106.426507\t551693.65\t551693.65\n",
    "                year\t2015.00\t2016.147899\t2018.00\t3.00\n",
    "                \n",
    "                Using above data we can summarize that:\n",
    "                \n",
    "                Averagerice column values seem ok.\n",
    "                Total volume feature has 84.56,850644.013009,62505646.52 as min , mean and max values and thats highly varrying.\n",
    "                Minimum values of all the rest features is zero that indicates something is wrong.\n",
    "                Difference between mean and max values of all features is very large.\n",
    "                \n",
    "            Categorical columns summary:\n",
    "            \n",
    "                'Date' column has 169 unique entries with top modt frequency of 108 being 2015-12-27.\n",
    "                \n",
    "                In 'type' column, ['conventional', 'organic'] 2 unique entries are there , topmost 9126, being conventional.\n",
    "                \n",
    "                Most occuring region is Albany with 338 frequencies.\n",
    "                \n",
    "                i.e. \n",
    "                \n",
    "                For Date , most frequent value is:  ModeResult(mode=array(['2015-01-04'], dtype=object), count=array([108]))\n",
    "                For type , most frequent value is:  ModeResult(mode=array(['conventional'], dtype=object), count=array([9126]))\n",
    "                For region , most frequent value is:  ModeResult(mode=array(['Albany'], dtype=object), count=array([338]))\n",
    "\n",
    "5. Exploring unique values in categorical columns:\n",
    "\n",
    " For column Date unique values are:  ['2015-12-27' '2015-12-20' '2015-12-13' '2015-12-06' '2015-11-29'\n",
    " '2015-11-22' '2015-11-15' '2015-11-08' '2015-11-01' '2015-10-25'\n",
    " '2015-10-18' '2015-10-11' '2015-10-04' '2015-09-27' '2015-09-20'\n",
    " '2015-09-13' '2015-09-06' '2015-08-30' '2015-08-23' '2015-08-16'\n",
    " '2015-08-09' '2015-08-02' '2015-07-26' '2015-07-19' '2015-07-12'\n",
    " '2015-07-05' '2015-06-28' '2015-06-21' '2015-06-14' '2015-06-07'\n",
    " '2015-05-31' '2015-05-24' '2015-05-17' '2015-05-10' '2015-05-03'\n",
    " '2015-04-26' '2015-04-19' '2015-04-12' '2015-04-05' '2015-03-29'\n",
    " '2015-03-22' '2015-03-15' '2015-03-08' '2015-03-01' '2015-02-22'\n",
    " '2015-02-15' '2015-02-08' '2015-02-01' '2015-01-25' '2015-01-18'\n",
    " '2015-01-11' '2015-01-04' '2016-12-25' '2016-12-18' '2016-12-11'\n",
    " '2016-12-04' '2016-11-27' '2016-11-20' '2016-11-13' '2016-11-06'\n",
    " '2016-10-30' '2016-10-23' '2016-10-16' '2016-10-09' '2016-10-02'\n",
    " '2016-09-25' '2016-09-18' '2016-09-11' '2016-09-04' '2016-08-28'\n",
    " '2016-08-21' '2016-08-14' '2016-08-07' '2016-07-31' '2016-07-24'\n",
    " '2016-07-17' '2016-07-10' '2016-07-03' '2016-06-26' '2016-06-19'\n",
    " '2016-06-12' '2016-06-05' '2016-05-29' '2016-05-22' '2016-05-15'\n",
    " '2016-05-08' '2016-05-01' '2016-04-24' '2016-04-17' '2016-04-10'\n",
    " '2016-04-03' '2016-03-27' '2016-03-20' '2016-03-13' '2016-03-06'\n",
    " '2016-02-28' '2016-02-21' '2016-02-14' '2016-02-07' '2016-01-31'\n",
    " '2016-01-24' '2016-01-17' '2016-01-10' '2016-01-03' '2017-12-31'\n",
    " '2017-12-24' '2017-12-17' '2017-12-10' '2017-12-03' '2017-11-26'\n",
    " '2017-11-19' '2017-11-12' '2017-11-05' '2017-10-29' '2017-10-22'\n",
    " '2017-10-15' '2017-10-08' '2017-10-01' '2017-09-24' '2017-09-17'\n",
    " '2017-09-10' '2017-09-03' '2017-08-27' '2017-08-20' '2017-08-13'\n",
    " '2017-08-06' '2017-07-30' '2017-07-23' '2017-07-16' '2017-07-09'\n",
    " '2017-07-02' '2017-06-25' '2017-06-18' '2017-06-11' '2017-06-04'\n",
    " '2017-05-28' '2017-05-21' '2017-05-14' '2017-05-07' '2017-04-30'\n",
    " '2017-04-23' '2017-04-16' '2017-04-09' '2017-04-02' '2017-03-26'\n",
    " '2017-03-19' '2017-03-12' '2017-03-05' '2017-02-26' '2017-02-19'\n",
    " '2017-02-12' '2017-02-05' '2017-01-29' '2017-01-22' '2017-01-15'\n",
    " '2017-01-08' '2017-01-01' '2018-03-25' '2018-03-18' '2018-03-11'\n",
    " '2018-03-04' '2018-02-25' '2018-02-18' '2018-02-11' '2018-02-04'\n",
    " '2018-01-28' '2018-01-21' '2018-01-14' '2018-01-07']\n",
    " For column Date count of unique values are:  169 \n",
    "\n",
    "\n",
    "For column type unique values are:  ['conventional' 'organic']\n",
    "For column type count of unique values are:  2 \n",
    "\n",
    "\n",
    "For column region unique values are:  ['Albany' 'Atlanta' 'BaltimoreWashington' 'Boise' 'Boston'\n",
    " 'BuffaloRochester' 'California' 'Charlotte' 'Chicago' 'CincinnatiDayton'\n",
    " 'Columbus' 'DallasFtWorth' 'Denver' 'Detroit' 'GrandRapids' 'GreatLakes'\n",
    " 'HarrisburgScranton' 'HartfordSpringfield' 'Houston' 'Indianapolis'\n",
    " 'Jacksonville' 'LasVegas' 'LosAngeles' 'Louisville' 'MiamiFtLauderdale'\n",
    " 'Midsouth' 'Nashville' 'NewOrleansMobile' 'NewYork' 'Northeast'\n",
    " 'NorthernNewEngland' 'Orlando' 'Philadelphia' 'PhoenixTucson'\n",
    " 'Pittsburgh' 'Plains' 'Portland' 'RaleighGreensboro' 'RichmondNorfolk'\n",
    " 'Roanoke' 'Sacramento' 'SanDiego' 'SanFrancisco' 'Seattle'\n",
    " 'SouthCarolina' 'SouthCentral' 'Southeast' 'Spokane' 'StLouis' 'Syracuse'\n",
    " 'Tampa' 'TotalUS' 'West' 'WestTexNewMexico']\n",
    "For column region count of unique values are:  54 \n",
    "\n",
    "6. Value Counts: \n",
    "\n",
    "\n",
    "Value counts of each date are 108 for all except 107 for 2015-12-06.\n",
    "\n",
    "Both types of avocadoes have 9126 data entries.\n",
    "\n",
    "Regions, 'Albany' 'Atlanta' 'BaltimoreWashington' 'Boise' 'Boston'\n",
    " 'BuffaloRochester' 'California' 'Charlotte' 'Chicago' 'CincinnatiDayton'\n",
    " 'Columbus' 'DallasFtWorth' 'Denver' 'Detroit' 'GrandRapids' 'GreatLakes'\n",
    " 'HarrisburgScranton' 'HartfordSpringfield' 'Houston' 'Indianapolis'\n",
    " 'Jacksonville' 'LasVegas' 'LosAngeles' 'Louisville' 'MiamiFtLauderdale'\n",
    " 'Midsouth' 'Nashville' 'NewOrleansMobile' 'NewYork' 'Northeast'\n",
    " 'NorthernNewEngland' 'Orlando' 'Philadelphia' 'PhoenixTucson'\n",
    " 'Pittsburgh' 'Plains' 'Portland' 'RaleighGreensboro' 'RichmondNorfolk'\n",
    " 'Roanoke' 'Sacramento' 'SanDiego' 'SanFrancisco' 'Seattle'\n",
    " 'SouthCarolina' 'SouthCentral' 'Southeast' 'Spokane' 'StLouis' 'Syracuse'\n",
    " 'Tampa' 'TotalUS' 'West' have 338 entries whereas 'WestTexNewMexico'\n",
    " has 337.\n",
    " \n",
    "\n",
    "7. Grouping features on the basis of Averageprice, we can see that for \n",
    "   year 2017, average price is highest.\n",
    "   \n",
    "8. Creating new date feature for Date , Month , Year data respectively.\n",
    "\n",
    "    Creating Average price range categorical feature having values less, middle and high.\n",
    "\n",
    "\n",
    "9. Univariate analysis:\n",
    "\n",
    "    Countplot:\n",
    "            For days 25,18,11,4 we can see highest counts.\n",
    "\n",
    "            1 month has highest count.\n",
    "\n",
    "            2015,16,17 has highest counts as compared to 2018.\n",
    "\n",
    "            Type and region features nearly have the same counts.\n",
    "            \n",
    "    Histogram:\n",
    "            \n",
    "            \n",
    "10. Bivariate analysis:\n",
    "        Catplot:\n",
    "            By grouping data on the basis of price we can see that\n",
    "            price range was average i.e. between 1 and 2 units for most of features.\n",
    "            \n",
    "            \n",
    "            Avocados were high priced during the month 1 and 2.\n",
    "            Average price was also high 1,2,3 months.\n",
    "            Price was lowest during 8,9,10,11,12th month.\n",
    "            \n",
    "            Checking average prices on years:\n",
    "            \n",
    "            Avocados were considerably high priced i.e. greater than 2 in the year 2016.\n",
    "            \n",
    "            Average prices were also high for 2017 and 2015.\n",
    "            \n",
    "            Sales counts and prices were really low for the year 2018.\n",
    "            \n",
    "11. Multivariate analysis:\n",
    "        \n",
    "        Splitting months into three halves:\n",
    "            \n",
    "            Avgprice remained quite uniform throught the month and days \n",
    "            as well but some outliers can be seen in days vs avg price.\n",
    "            \n",
    "            For the year 2018, avgprice remained below 2.25 units.\n",
    "            \n",
    "            \n",
    "        Combining scatter and regression plot for multivariate analysis btw features, avgPrice and type as hue:\n",
    "        \n",
    "            In general, Total bags, Small Bags, XLarge Bags, Total Volume, 4046 plu type, 4225 plu type, 4770 plu type show slight\n",
    "            negative relation with target.\n",
    "            \n",
    "            A strong correlation can be seen between nearly all features and avgPrice when avocados are organic type.\n",
    "            \n",
    "            A weak correlation can be seen between nearly all features and avgPrice when avocados are conventional type.\n",
    "            \n",
    "            \n",
    "12. Outliers:\n",
    "All bags, plu types, and avgprice features contain huge quantity of outliers.\n",
    "\n",
    "13. Skewness in data: \n",
    "\n",
    "Following features are highly skewed that is also confirmed by the presence of outliers.\n",
    "4046             \n",
    "4225             \n",
    "Total Volume     \n",
    "Small Bags       \n",
    "Total Bags      \n",
    "Large Bags       \n",
    "4770            \n",
    "XLarge Bags     \n",
    "\n",
    "Following features are not skewed:\n",
    "Day              \n",
    "Month            \n",
    "Year             \n",
    "year             \n",
    "AveragePrice \n",
    "\n",
    "14. Using zscore outlier removal technique to remove data having more than 3 times standard deviation value.\n",
    "\n",
    "Thus we have removed 598.0 number of outliers that is 3.27 percent of outlier data.\n",
    "\n",
    "Still we can see that skewness values are not within permissible limits.\n",
    "\n",
    "15. Correlation btw features and label:\n",
    "\n",
    "Plu types, bags and total volume features are negatively correlated with Average price and\n",
    "Day, month and year has most positive correlation with average price.\n",
    "\n",
    "16. Heatmap confirms multicollinearity problem between bags and year features.\n",
    "\n",
    "We will remove it with principal component analysis and variance inflation factor methods.\n",
    "\n",
    "As vif values of bags and plu types are more than 5, multicollinearity problem exists and we will correct it furthur.\n",
    "\n",
    "For regression analysis,\n",
    "\n",
    "17. Furthur we have used get_dummies, power transformer and scree plot to confirm the most important features for building ml model.\n",
    "\n",
    "Out of 72 features after encoding and applying pca, we have selected 55 most importnat features for furthur analysis.\n",
    "\n",
    "Now chicking the skewness, we have got rid of all skewness in data. Thus our data is now fit for ml model building.\n",
    "\n",
    "18. For regression problem we have used linear regression, lasso, ridge, xgboost, decision tree, random forest, svm, knn.\n",
    "\n",
    "For classification,\n",
    " Our label is region.\n",
    " Using label encoder and applying pca, we are left with 12 most important features responsible for our analysis and ml\n",
    " model building.\n",
    "\n",
    " We have used logistic regression decision tree clasifier, SVC , Random forest classifier, knn classifier,\n",
    " gradient boosting classifier, ada boost classifier, naive bayes classifier.\n",
    " \n",
    "19. Best regression nodel,\n",
    "\n",
    "    We have got best score with ensemble technique using Random forest regressor model.\n",
    "    Result is mentioned below:\n",
    "    \n",
    "        MAE:  0.10620936555891237\n",
    "        MSE:  0.021871604856495468\n",
    "        RMSE:  0.14789051645218995\n",
    "        R2:  0.8547174582125039\n",
    "        \n",
    "20. Best classifier model: RandomForestClassifier, result shared below.\n",
    "\n",
    "Training accuracy:  100.0\n",
    "Testing accuracy:  86.34818731117825\n",
    "Confusion matrix: \n",
    " [[88  0  0 ...  0  0  0]\n",
    " [ 0 79  0 ...  0  0  2]\n",
    " [ 0  0 97 ...  0  0  0]\n",
    " ...\n",
    " [ 0  0  0 ... 49  0  0]\n",
    " [ 0  0  0 ...  0 78  0]\n",
    " [ 0  1  2 ...  0  0 64]]\n",
    "classification report:                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.95      0.90        93\n",
    "           1       0.72      0.77      0.75       102\n",
    "           2       0.92      0.97      0.94       100\n",
    "           3       0.96      0.87      0.91       104\n",
    "           4       0.91      0.93      0.92       104\n",
    "           5       0.99      0.82      0.90        97\n",
    "           6       0.97      0.90      0.94        84\n",
    "           7       0.84      0.90      0.87       106\n",
    "           8       0.95      0.97      0.96       119\n",
    "           9       0.85      0.83      0.84        93\n",
    "          10       0.79      0.79      0.79       113\n",
    "          11       0.82      0.87      0.84       104\n",
    "          12       0.87      1.00      0.93        97\n",
    "          13       0.71      0.75      0.73        89\n",
    "          14       0.89      0.91      0.90        93\n",
    "          15       0.92      1.00      0.96        79\n",
    "          16       0.94      0.93      0.93        98\n",
    "          17       0.91      0.91      0.91        95\n",
    "          18       0.85      0.91      0.88        97\n",
    "          19       0.80      0.87      0.84        87\n",
    "          20       0.89      0.86      0.87       100\n",
    "          21       0.72      0.70      0.71       105\n",
    "          22       0.94      0.94      0.94       102\n",
    "          23       0.82      0.89      0.86       100\n",
    "          24       0.67      0.61      0.64       112\n",
    "          25       0.97      0.98      0.97        97\n",
    "          26       0.77      0.81      0.79       104\n",
    "          27       0.81      0.86      0.83        96\n",
    "          28       0.96      0.94      0.95        94\n",
    "          29       1.00      0.98      0.99       100\n",
    "          30       0.93      0.92      0.93       105\n",
    "          31       0.63      0.56      0.59       105\n",
    "          32       0.93      0.83      0.88       109\n",
    "          33       0.79      0.86      0.82       100\n",
    "          34       0.98      0.92      0.95       111\n",
    "          35       0.91      0.95      0.93        91\n",
    "          36       0.88      0.77      0.82       104\n",
    "          37       0.82      0.81      0.81        99\n",
    "          38       0.83      0.85      0.84       116\n",
    "          39       0.87      0.84      0.85       105\n",
    "          40       0.85      0.96      0.90       112\n",
    "          41       0.83      0.84      0.84       102\n",
    "          42       0.92      0.91      0.92        78\n",
    "          43       0.89      0.88      0.89        93\n",
    "          44       0.88      0.81      0.84       100\n",
    "          45       0.99      0.98      0.98        85\n",
    "          46       0.99      0.97      0.98        96\n",
    "          47       0.91      0.83      0.87       102\n",
    "          48       0.92      0.79      0.85        98\n",
    "          49       0.84      0.92      0.88        97\n",
    "          50       0.52      0.53      0.53       109\n",
    "          51       1.00      1.00      1.00        49\n",
    "          52       1.00      1.00      1.00        78\n",
    "          53       0.80      0.73      0.76        88\n",
    "\n",
    "    accuracy                           0.86      5296\n",
    "   macro avg       0.87      0.87      0.87      5296\n",
    "weighted avg       0.86      0.86      0.86      5296\n",
    "\n",
    "We have furthur used gris search cv to improve our result and created the pipeline.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing and Normalizing data:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "# Spliting data\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "# Importing metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "# Removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947cc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imp libs:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Spliting data\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Importing metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e32cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc =\"https://raw.githubusercontent.com/dsrscientist/Data-Science-ML-Capstone-Projects/master/avocado.csv\"\n",
    "df = pd.read_csv(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884aed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99207137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99082d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14907f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194cf0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b801091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556a5ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "desc = df.describe().T\n",
    "desc['range']=desc['max']-desc['min']\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ac548",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc[['min','mean','max','range']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_data = df.select_dtypes(include=['int64','float64'])\n",
    "\n",
    "cat_data= df.select_dtypes(include=['object'])\n",
    "\n",
    "cont_columns = cont_data.columns\n",
    "\n",
    "cat_columns = cat_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for i in cat_columns:\n",
    "    print('For',i,', most frequent value is: ',stats.mode(df[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_columns:\n",
    "    print('For column',i,'unique values are: ',df[i].unique())\n",
    "    print('For column',i,'count of unique values are: ',df[i].nunique(),'\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477bc637",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_columns:\n",
    "    print('For column --',i,'-- value counts are: \\n',df[i].value_counts(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74fc458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=\"Date\").AveragePrice.mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1326a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=\"region\").AveragePrice.mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c905fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=\"Total Volume\").AveragePrice.mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=\"Total Bags\").AveragePrice.mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a93809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=\"Small Bags\").AveragePrice.mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255214ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=\"year\").AveragePrice.mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9933e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Year','Month','Day']] = df['Date'].str.split('-',expand=True)\n",
    "\n",
    "pd.to_numeric(df['Day'])\n",
    "pd.to_numeric(df['Month'])\n",
    "pd.to_numeric(df['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbafcc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbba0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Day','Month','Year','type','region','Total Volume','4046','4225','4770','Total Bags',\n",
    "        'Small Bags','Large Bags','XLarge Bags','year','AveragePrice']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_data = df.select_dtypes(include=['int64','float64'])\n",
    "\n",
    "cat_data= df.select_dtypes(include=['object'])\n",
    "\n",
    "cont_columns = cont_data.columns\n",
    "\n",
    "cat_columns = cat_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546adb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcdf2a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Univariate analysis:\n",
    "\n",
    "for i in cat_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.countplot(x=df[i],data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AveragePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36378fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "AvgPr = []\n",
    "for i in df.AveragePrice:\n",
    "    if i < 1:\n",
    "        AvgPr.append('Less')\n",
    "    elif i < 2 and i > 1:\n",
    "        AvgPr.append('Avg')\n",
    "    else:\n",
    "        AvgPr.append('High')\n",
    "        \n",
    "df['Avg Price Range'] = AvgPr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268da414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Avg Price Range'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf6fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking counts btw rel and avg price by region\n",
    "\n",
    "f= plt.figure(figsize=(12,50))\n",
    "ax = sns.catplot(x=\"region\", kind=\"count\",hue = 'Avg Price Range', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking counts btw day and avg price by region\n",
    "\n",
    "sns.catplot(x=\"Day\", kind=\"count\",hue = 'Avg Price Range', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7dd717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=\"Day\").AveragePrice.mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b41718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking counts btw month and avg price by region\n",
    "\n",
    "sns.catplot(x=\"Month\", kind=\"count\",hue = 'Avg Price Range', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking counts btw rel and avg price by region\n",
    "\n",
    "sns.catplot(x=\"year\", kind=\"count\",hue = 'Avg Price Range', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Day','Month','Year']] = df[['Day','Month','Year']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "MonthPeriod = []\n",
    "for i in df.Day:\n",
    "    if i < 10:\n",
    "        MonthPeriod.append('One Third Period')\n",
    "    elif i < 20 and i > 10:\n",
    "        MonthPeriod.append('2/3rd Period')\n",
    "    else:\n",
    "        MonthPeriod.append('Last Period')\n",
    "        \n",
    "df['Month Period'] = MonthPeriod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc59335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking counts btw region and day by region\n",
    "\n",
    "sns.catplot(x=\"Day\", kind=\"count\",hue = 'region', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad49107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking counts btw region and month by region\n",
    "\n",
    "sns.catplot(x=\"Month\", kind=\"count\",hue = 'region', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking counts btw region and year price by region\n",
    "\n",
    "sns.catplot(x=\"year\", kind=\"count\",hue = 'region', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9769ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990aa0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = \"Month Period\", y = \"AveragePrice\", palette = \"Set2\", data = df)\n",
    "\n",
    "sns.catplot(x = \"Day\", y = \"AveragePrice\", palette = \"Set2\", data = df)\n",
    "\n",
    "sns.catplot(x = \"Month\", y = \"AveragePrice\", palette = \"Set2\", data = df)\n",
    "\n",
    "sns.catplot(x = \"year\", y = \"AveragePrice\", palette = \"Set2\", data = df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754960a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions=df['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a33552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot btw columns and Charges: \n",
    "\n",
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Total Bags\", y = \"AveragePrice\", data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7828c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot btw columns and Charges: \n",
    "\n",
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Total Bags\", y = \"AveragePrice\", data=df,hue='type', palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Small Bags\", y = \"AveragePrice\", data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a75caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Small Bags\", y = \"AveragePrice\",hue='type', data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d82b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"XLarge Bags\", y = \"AveragePrice\", data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"XLarge Bags\", y = \"AveragePrice\",hue='type', data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b527f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Total Volume\", y = \"AveragePrice\", data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb23821",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"Total Volume\", y = \"AveragePrice\",hue='type', data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"4046\", y = \"AveragePrice\", data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d278a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"4046\", y = \"AveragePrice\", data=df,hue='type', palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"4225\", y = \"AveragePrice\", data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894214c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"4225\", y = \"AveragePrice\",hue='type', data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"4770\", y = \"AveragePrice\", data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eaccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"4770\", y = \"AveragePrice\",hue='type', data=df, palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e808861",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(12,5))\n",
    "ax =sns.lmplot(x = \"year\", y = \"AveragePrice\", data=df, hue='region',palette='Set2', height=8, aspect=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de03418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot:\n",
    "\n",
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(10,6),facecolor='orange')\n",
    "    plt.hist(df[i],bins=10)\n",
    "    plt.xlabel(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of continuous variables:\n",
    "\n",
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.distplot(df[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the outliers in continuous variables:\n",
    "\n",
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.boxplot(df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36275b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Day','Month','Year','Month Period','type','region','Total Volume','4046','4225','4770','Total Bags',\n",
    "        'Small Bags','Large Bags','XLarge Bags','year','AveragePrice']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8085905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.skew().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff234bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee181da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Z Statistics to check and remove any more outliers:\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_score = zscore(df[cont_columns])\n",
    "\n",
    "abs_z_score = np.abs(z_score)\n",
    "\n",
    "filtering_entry = (abs_z_score < 3).all(axis=1) # values lying in 3 times std will be removed\n",
    "\n",
    "df = df[filtering_entry]\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "18249-17651.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "598.0/18249*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of continuous variables:\n",
    "\n",
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(12,7),facecolor='orange')\n",
    "    sns.distplot(df[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30837ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac24f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features and label:\n",
    "\n",
    "# Replacing attrition column values:\n",
    "\n",
    "df.drop(columns = 'AveragePrice',axis = 1).corrwith(df.AveragePrice).plot(kind='bar',grid=True,figsize=(10,7),title='corelation between features and labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr().abs()\n",
    "plt.figure(figsize=(25,22))\n",
    "sns.heatmap(df_corr,annot=True,annot_kws={'size':10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80177cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['vif'] = [variance_inflation_factor(df[cont_columns],i) for i in range(df[cont_columns].shape[1])]\n",
    "vif['features'] = df[cont_columns].columns\n",
    "vif\n",
    "\n",
    "# These number indicate that if vif value < 5 , \n",
    "# multicolinearity problem exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf095f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19508cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop('year',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84fd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b7bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_new.columns:\n",
    "    print(i ,':',df_new[i].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "data_trans = pt.fit_transform(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e95c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and label:\n",
    "\n",
    "y = df_new['AveragePrice']\n",
    "X = df_new.drop('AveragePrice',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28472723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "X_trans = pt.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c5ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Using PCA i.e. Principal Component Analysis that is a diamensionallity reduction technique:\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit_transform(X_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scree Plot to identify best components:\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Covered')\n",
    "plt.title('PCA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=55)\n",
    "new_pcomp = pca.fit_transform(X_trans)\n",
    "princi_comp = pd.DataFrame(new_pcomp)\n",
    "princi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea16743",
   "metadata": {},
   "outputs": [],
   "source": [
    "princi_comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53509b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in princi_comp.columns:\n",
    "    print(i ,':',princi_comp[i].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data to training data and testing data\n",
    "# x_train,x_test,y_train,y_test\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(princi_comp,y,test_size=0.30,random_state=1)\n",
    "\n",
    "# Here we are keeping training data as our scalled data and testing data as our label or target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18bc029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOdel instantiating and training\n",
    "\n",
    "rm = LinearRegression()\n",
    "rm.fit(x_train,y_train) \n",
    "# here we will pass training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1455d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our model with Adjusted R2 Square: \n",
    "\n",
    "# on training data\n",
    "\n",
    "rm.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb89bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLotting and visualizing\n",
    "\n",
    "y_pred = rm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf70112",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('Actual Charges')\n",
    "plt.ylabel('Predicted Charges')\n",
    "plt.title('Actual vs Model Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: MAE , MSE , RMSE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "mean_absolute_error(y_test,y_pred) # 4 % error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11077261",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,y_pred) # lesser the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41efe274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score: \", rm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso,RidgeCV,LassoCV\n",
    "\n",
    "lassocv = LassoCV(alphas = None , max_iter = 100, normalize = True)\n",
    "lassocv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best alpha parameter\n",
    "alpha = lassocv.alpha_ # Best alpha rate\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now since we have the best parameter, lasso regression will be used:\n",
    "lasso_reg = Lasso(alpha)\n",
    "lasso_reg.fit(x_train,y_train)\n",
    "# i.e. when model is training it will learn at this speed 6...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbb0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Method:\n",
    "\n",
    "ridgecv = RidgeCV(alphas = np.arange(0.001,0.1,0.01),normalize = True)\n",
    "ridgecv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv.alpha_ # Best alpha rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha = ridgecv.alpha_)\n",
    "ridge_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea99f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model performance\n",
    "\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: \", metrics.mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"R2: \", metrics.r2_score(y_test, y_pred), \"\\n\")\n",
    "print(\"Score: \", rm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636decd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rm.coef_)\n",
    "print(f\"{rm.intercept_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using decision tree:\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_preddt = model.predict(x_test)\n",
    "\n",
    "r2_score(y_test,y_preddt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc948418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest:\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor_rf = RandomForestRegressor(n_estimators = 100)\n",
    "\n",
    "regressor_rf.fit(x_train, y_train)\n",
    "\n",
    "lr_normal_rf = regressor_rf.score(x_train, y_train)\n",
    "\n",
    "lr_normal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813091b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predrf = regressor_rf.predict(x_test)\n",
    "\n",
    "lr_normal_rf_test = regressor_rf.score(x_test, y_test)\n",
    "\n",
    "lr_normal_rf_test\n",
    "\n",
    "mse_lr_normal_rf  = mean_absolute_error(y_test, y_predrf)\n",
    "\n",
    "mse_lr_normal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: MAE , MSE , RMSE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_predrf))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test, y_predrf))\n",
    "print(\"RMSE: \", metrics.mean_squared_error(y_test, y_predrf, squared=False))\n",
    "print(\"R2: \", metrics.r2_score(y_test, y_predrf), \"\\n\")\n",
    "print(\"Score: \", regressor_rf.score(x_test, y_predrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31094efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Support vector regressor:\n",
    "\n",
    "# Fit the model over the training data\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "svr.fit(x_train, y_train)\n",
    "\n",
    "y_predsvr = svr.predict(x_test)\n",
    "\n",
    "r2_score(y_test,y_predsvr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454cfddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using XGBoost:\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor()\n",
    "xgb_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using XGBoost:\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor()\n",
    "xgb_clf.fit(x_train,y_train)\n",
    "\n",
    "y_predx = xgb_clf.predict(x_test)\n",
    "\n",
    "r2_score(y_test,y_predx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for xgboost model\n",
    "\n",
    "params = {\"learning_rate\"    : [0.05, 0.10] ,\n",
    "         \"max_depth\"        : [ 3, 5, 8, 12]}\n",
    "\n",
    "grd = GridSearchCV(xgb_clf,param_grid=params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c41028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_boosted = grd.fit(x_train,y_train)\n",
    "\n",
    "y_predxx = xgb_boosted.predict(x_test)\n",
    "\n",
    "r2_score(y_test,y_predxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f177d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Evaluation: MAE , MSE , RMSE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_predxx))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test, y_predxx))\n",
    "print(\"RMSE: \", metrics.mean_squared_error(y_test, y_predxx, squared=False))\n",
    "print(\"R2: \", metrics.r2_score(y_test, y_predxx), \"\\n\")\n",
    "print(\"Score: \", xgb_boosted.score(x_test, y_predxx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Innitiate k neighbour Regressor:\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "knnmodel = GridSearchCV(knn, params, cv=5)\n",
    "knnmodel.fit(x_train,y_train)\n",
    "knnmodel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best = KNeighborsRegressor(n_neighbors = 2)\n",
    "knn_best.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predknn = knn_best.predict(x_test)\n",
    "\n",
    "r2_score(y_test,y_predknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cadb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl = df.copy()\n",
    "df_cl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa57436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and label:\n",
    "\n",
    "y = df_cl['region']\n",
    "X = df_cl.drop('region',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f43de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding training data:\n",
    "X_dummies = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding lables:\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl = LabelEncoder()\n",
    "y_enc = lbl.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a2dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data to training data and testing data\n",
    "# x_train,x_test,y_train,y_test\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(princi_comp,y_enc,test_size=0.30,random_state=1)\n",
    "\n",
    "# Here we are keeping training data as our scalled data and testing data as our label or target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9497e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "X_trans = pt.fit_transform(X_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9df331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Using PCA i.e. Principal Component Analysis that is a diamensionallity reduction technique:\n",
    "\n",
    "pca1 = PCA()\n",
    "pca1.fit_transform(X_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ad6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scree Plot to identify best components:\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca1.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Covered')\n",
    "plt.title('PCA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8cc27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=12)\n",
    "new_pcomp = pca1.fit_transform(X_trans)\n",
    "princi_comp = pd.DataFrame(new_pcomp)\n",
    "princi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "princi_comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b35aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in princi_comp.columns:\n",
    "    print(i ,':',princi_comp[i].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res, X_test, y_train_res, y_test = train_test_split(princi_comp, y_enc, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d475a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best random state for logistic regression model:\n",
    "\n",
    "maxAccu = 0\n",
    "maxRS = 0\n",
    "\n",
    "for i in range(1,200):\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train_res,y_train_res) \n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Testing accuracy: ', acc, 'at random state', i)\n",
    "    \n",
    "    if acc > maxAccu:\n",
    "        maxAccu = acc\n",
    "        maxRS = i\n",
    "        print('Max accuracy',maxAccu,'max random state',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression:\n",
    "\n",
    "log_reg = LogisticRegression(random_state=1)\n",
    "\n",
    "log_reg.fit(X_train_res,y_train_res) \n",
    "\n",
    "pred_train = log_reg.predict(X_train_res)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "\n",
    "clr = classification_report(y_test,y_pred)\n",
    "\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88518cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best result for Decision Tree Classifier:\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=1)\n",
    "dtc.fit(X_train_res,y_train_res) \n",
    "pred_train_dtc = dtc.predict(X_train_res)\n",
    "y_pred = dtc.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_dtc)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06112e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forrest classifier model:\n",
    "\n",
    "rfc_f = RandomForestClassifier()\n",
    "rfc_f.fit(X_train_res,y_train_res) \n",
    "pred_train_rfc_f = rfc_f.predict(X_train_res)\n",
    "y_pred = rfc_f.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_rfc_f)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using best parameters for improved score:\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train_res,y_train_res)\n",
    "\n",
    "pred_train_svc = svc.predict(X_train_res)\n",
    "y_pred = svc.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_svc)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier:\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_res,y_train_res) \n",
    "pred_train_knn = knn.predict(X_train_res)\n",
    "y_pred = knn.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_knn)*100)\n",
    "print('Testing accuracy: ', acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba4b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# GBC\n",
    "\n",
    "gbdt_clf = GradientBoostingClassifier(random_state=3)\n",
    "gbdt_clf.fit(X_train_res,y_train_res) \n",
    "pred_train_gbdt_clf = gbdt_clf.predict(X_train_res)\n",
    "y_pred = gbdt_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_gbdt_clf)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADA model:\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_boosted = AdaBoostClassifier()\n",
    "ada_boosted.fit(X_train_res,y_train_res)\n",
    "yb_pred = ada_boosted.predict(X_test)\n",
    "pred_train_ada = ada_boosted.predict(X_train_res)\n",
    "y_pred = ada_boosted.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_ada)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b222a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train_res, y_train_res)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "  \n",
    "# accuracy on X_test\n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosing best models for classification and regression problems:\n",
    "\n",
    "# Regression:\n",
    "\n",
    "# Random forest:\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor_rf = RandomForestRegressor(n_estimators = 100)\n",
    "\n",
    "regressor_rf.fit(x_train, y_train)\n",
    "\n",
    "lr_normal_rf = regressor_rf.score(x_train, y_train)\n",
    "\n",
    "lr_normal_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f81025",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predrf = regressor_rf.predict(x_test)\n",
    "\n",
    "lr_normal_rf_test = regressor_rf.score(x_test, y_test)\n",
    "\n",
    "lr_normal_rf_test\n",
    "\n",
    "mse_lr_normal_rf  = mean_absolute_error(y_test, y_predrf)\n",
    "\n",
    "mse_lr_normal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: MAE , MSE , RMSE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_predrf))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test, y_predrf))\n",
    "print(\"RMSE: \", metrics.mean_squared_error(y_test, y_predrf, squared=False))\n",
    "print(\"R2: \", metrics.r2_score(y_test, y_predrf), \"\\n\")\n",
    "print(\"Score: \", regressor_rf.score(x_test, y_predrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16918576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a70728",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1207c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predrf = base_model.predict(x_test)\n",
    "\n",
    "lr_normal_rf_test = base_model.score(x_test, y_test)\n",
    "\n",
    "lr_normal_rf_test\n",
    "\n",
    "mse_lr_normal_rf  = mean_absolute_error(y_test, y_predrf)\n",
    "\n",
    "mse_lr_normal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd092fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_predrf))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test, y_predrf))\n",
    "print(\"RMSE: \", metrics.mean_squared_error(y_test, y_predrf, squared=False))\n",
    "print(\"R2: \", metrics.r2_score(y_test, y_predrf), \"\\n\")\n",
    "print(\"Score: \", regressor_rf.score(x_test, y_predrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75947e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8135d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1 = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae92be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predrf = base_model1.predict(x_test)\n",
    "\n",
    "lr_normal_rf_test = base_model1.score(x_test, y_test)\n",
    "\n",
    "lr_normal_rf_test\n",
    "\n",
    "mse_lr_normal_rf  = mean_absolute_error(y_test, y_predrf)\n",
    "\n",
    "mse_lr_normal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbd07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random forrest classifier model for solving classification problem and futhur applying hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afedea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res, X_test, y_train_res, y_test = train_test_split(princi_comp, y_enc, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e4b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forrest classifier model:\n",
    "\n",
    "rfc_f = RandomForestClassifier()\n",
    "rfc_f.fit(X_train_res,y_train_res) \n",
    "pred_train_rfc_f = rfc_f.predict(X_train_res)\n",
    "y_pred = rfc_f.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_rfc_f)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can furthur use Cross validation methods to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50096d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline:\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe1 = Pipeline([('pt',PowerTransformer()),('pca',PCA(n_components=55)),('base_model1',RandomForestRegressor(n_estimators = 10, random_state = 42))])\n",
    "\n",
    "pipe1.fit(x_train,y_train)\n",
    "\n",
    "y_pred = pipe.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03ae74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving regression model to pickle string\n",
    "\n",
    "import pickle \n",
    "saved_model1 = pickle.dumps(pipe1) \n",
    "pipe_pickle1 = pickle.loads(saved_model1)\n",
    "pipe_pickle1.predict(X_test) # predicting testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443749bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline:\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe2 = Pipeline([('pt',PowerTransformer()),('pca1',PCA(n_components=12),('rfc_f',RandomForestClassifier()))])\n",
    "\n",
    "pipe2.fit(x_train,y_train)\n",
    "\n",
    "y_pred = pipe2.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f492f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving classifier model to pickle string\n",
    "\n",
    "import pickle \n",
    "saved_model2 = pickle.dumps(pipe2) \n",
    "pipe_pickle2 = pickle.loads(saved_model2)\n",
    "pipe_pickle2.predict(X_test) # predicting testing data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
